{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-31T17:38:48.944724Z",
     "start_time": "2025-01-31T17:38:48.938671Z"
    }
   },
   "source": [
    "import unicodedata\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\")) # jupyter notebook full-width display\n",
    "display(HTML(\"<style>.dataframe td { white-space: nowrap; }</style>\")) # no text wrapping\n",
    "\n",
    "# pandas formatting\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 200)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>.dataframe td { white-space: nowrap; }</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T15:47:19.314800Z",
     "start_time": "2025-01-31T15:47:19.106095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# all files that have been downloaded and parsed\n",
    "parsed_docs_folder = os.path.join(\"..\", \"ParsedPublications\")\n",
    "\n",
    "min_year = 2023\n",
    "parsed_files = list()\n",
    "parsed_files_with_hq_ocr = list()\n",
    "for folder in os.listdir(parsed_docs_folder):\n",
    "    path = os.path.join(parsed_docs_folder, folder)\n",
    "    if os.path.isdir(path):\n",
    "        for json_file in os.listdir(path):\n",
    "            if json_file.endswith(\".json\"):\n",
    "                parsed_files.append(json_file.replace('.json', ''))\n",
    "                if folder in [str(year) for year in range(min_year, 2024 + 1)]:\n",
    "                    parsed_files_with_hq_ocr.append(json_file.replace('.json', ''))\n",
    "\n",
    "# all files from website\n",
    "fr_eng_correlation_csv = \"fr_eng_correlation_data.csv\"\n",
    "fr_eng_correlation_df = pd.read_csv(fr_eng_correlation_csv)\n",
    "# exclude files that aren't downloaded, and files that have been withdrawn\n",
    "fr_eng_correlation_df = fr_eng_correlation_df[(fr_eng_correlation_df.filename_en.isin(parsed_files)) | (fr_eng_correlation_df.filename_fr.isin(parsed_files))]\n",
    "fr_eng_correlation_df = fr_eng_correlation_df[(fr_eng_correlation_df.filename_en != 'WITHDRAWN') & (fr_eng_correlation_df.filename_fr != 'WITHDRAWN')]\n",
    "\n",
    "# weblinks for previewing / checking results\n",
    "weblinks_df = fr_eng_correlation_df.copy()\n",
    "weblinks_df = weblinks_df[['pub_number', 'nom', 'name', 'url_fr', 'url_en', 'file_url_fr', 'file_url_en']]\n",
    "\n",
    "# data to be used for language classifier\n",
    "lang_df = fr_eng_correlation_df.copy()\n",
    "lang_df = lang_df[(lang_df.filename_fr.isin(parsed_files_with_hq_ocr)) & (lang_df.filename_en.isin(parsed_files_with_hq_ocr)) & (lang_df.filename_fr != lang_df.filename_en)]\n",
    "\n",
    "# scrabble dictionaries for removing questionable words\n",
    "with open('language_classifier/scrabble_dictionaries/en_scrabble.txt', 'r') as f:\n",
    "    en_scrabble = {line.lower().strip() for line in f}\n",
    "    \n",
    "with open('language_classifier/scrabble_dictionaries/fr_scrabble.txt', 'r') as f:\n",
    "    fr_scrabble = {line.lower().strip() for line in f}"
   ],
   "id": "83675b54298a8486",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# helper functions",
   "id": "ca8dc9ee3a7f7d60"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:52:30.652715Z",
     "start_time": "2025-01-31T16:52:30.638714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preview_publication(pub_number):\n",
    "    if type(pub_number) is pd.DataFrame and pub_number.shape[0] == 1:\n",
    "        try:\n",
    "            pub_number = pub_number['pub_number'].values[0]\n",
    "        except ValueError:\n",
    "            return None\n",
    "    elif type(pub_number) is pd.Series:\n",
    "        try:\n",
    "            pub_number = pub_number.values[0]\n",
    "        except ValueError:\n",
    "            return None\n",
    "    \n",
    "    try:\n",
    "        output_df = weblinks_df[weblinks_df.pub_number == pub_number].T\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "        \n",
    "    return output_df\n",
    "\n",
    "\n",
    "def get_filepaths(row, min_year=2023):\n",
    "    fr_filename, en_filename = row['filename_fr'] + '.json', row['filename_en'] + '.json'\n",
    "    file_folders = [os.path.join('..', 'ParsedPublications', str(year)) for year in range(min_year, 2024 + 1)]\n",
    "    \n",
    "    try:\n",
    "        fr_path, en_path = ([os.path.join(folder, fr_filename) for folder in file_folders if os.path.exists(os.path.join(folder, fr_filename))][0], \n",
    "                            [os.path.join(folder, en_filename) for folder in file_folders if os.path.exists(os.path.join(folder, en_filename))][0])\n",
    "    except IndexError:\n",
    "        return None, None\n",
    "    \n",
    "    return fr_path, en_path\n",
    "\n",
    "\n",
    "def remove_accents(word):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFKD', word) if not unicodedata.combining(c))\n",
    "\n",
    "\n",
    "def remove_non_scrabble_words(words, scrabble_dictionary):\n",
    "    return {word for word in words if remove_accents(word) in scrabble_dictionary}\n",
    "\n",
    "\n",
    "def test_wordlists(text_block, english_words, french_words):\n",
    "    en_count = sum(1 for word in text_block.split() if word in english_words)\n",
    "    fr_count = sum(1 for word in text_block.split() if word in french_words)\n",
    "    \n",
    "    print('english words:', list(word for word in text_block.split() if word in english_words))\n",
    "    print('french words:', list(word for word in text_block.split() if word in french_words))\n",
    "    print(f'{en_count=}, {fr_count=}')    \n",
    "    \n",
    "    \n",
    "def most_common_word_info(counter_obj, n=10):  \n",
    "    length = counter_obj.total()\n",
    "    c_v = 0\n",
    "    for k, v in counter_obj.most_common(n):\n",
    "        rng = f'({(100 * c_v) / length:.0f}%'\n",
    "        c_v += v\n",
    "        rng += f'-{(100 * c_v) / length:.0f}%)'\n",
    "        print(f'{k:<20}{v:>8}{(100 * v) / length:>8.0f}%{rng:>15}')\n",
    "\n",
    "\n",
    "def nth_percentile(p, counter_obj, greater_than=True):\n",
    "    sorted_list = sorted(counter_obj.items(), key=lambda x: x[1], reverse=greater_than)\n",
    "    index = max(min(len(sorted_list) - 1, int(len(sorted_list) * p)), 0)\n",
    "    \n",
    "    return sorted_list[index]\n",
    "\n",
    "\n",
    "def nth_percentile_weighted(p, counter_expanded, greater_than=True):\n",
    "    sorted_list = sorted(counter_expanded, key=lambda x: x[1], reverse=greater_than)\n",
    "    index = max(min(len(sorted_list) - 1, int(len(sorted_list) * p)), 0)\n",
    "    \n",
    "    return sorted_list[index]\n",
    "\n",
    "\n",
    "def count_nth_percentile(p, counter_obj, greater_than=True):\n",
    "    sorted_list = sorted(counter_obj.items(), key=lambda x: x[1], reverse=greater_than)\n",
    "    index = max(min(len(sorted_list) - 1, int(len(sorted_list) * p)), 0)\n",
    "    \n",
    "    return len(sorted_list[index:]) if greater_than else len(sorted_list[-max(index, 1):])\n",
    "\n",
    "\n",
    "def count_nth_percentile_weighted(p, counter_expanded, greater_than=True):\n",
    "    sorted_list = sorted(counter_expanded, key=lambda x: x[1], reverse=greater_than)\n",
    "    index = max(min(len(sorted_list) - 1, int(len(sorted_list) * p)), 0)\n",
    "    \n",
    "    count_if_gte = sorted_list[len(sorted_list) - index][1]\n",
    "    count_if_lte = sorted_list[index][1]\n",
    "        \n",
    "    gte = {x for x in counter_expanded if x[1] >= count_if_gte}\n",
    "    lte = {x for x in counter_expanded if x[1] <= count_if_lte}\n",
    "    \n",
    "    return len(gte) if greater_than else len(lte)\n",
    "\n",
    "\n",
    "def examples_at_word_count(n, counter_obj, n_samples=5, tolerance=0.1):\n",
    "    lower, upper = int((1 - 0.1) * n), int((1 + 0.1) * n)\n",
    "    all_examples = [k for k, v in counter_obj.items() if lower <= v <= upper]\n",
    "    \n",
    "    return random.sample(all_examples, min(n_samples, len(all_examples)))\n"
   ],
   "id": "83648ca204fa96b0",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T17:10:02.236545Z",
     "start_time": "2025-01-31T17:10:02.213416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_sentences_list(text, ref):\n",
    "    valid_word_regex = re.compile(r'^[a-zA-ZÀ-ÿ]+$')\n",
    "    min_length, max_length = 5, 20\n",
    "    sentences = []\n",
    "    \n",
    "    document_parts = re.split(ref, text, flags=re.IGNORECASE)\n",
    "    if 2 < len(document_parts) < 5:\n",
    "        text = document_parts[1]\n",
    "    \n",
    "    cleaned_text = re.sub(r'[^a-zA-ZÀ-ÿ.\\s]', '', text)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "\n",
    "    return [\n",
    "        sentence.strip() for sentence in cleaned_text.split('.')\n",
    "        if min_length <= len(sentence.split()) <= max_length\n",
    "        and all(valid_word_regex.match(word) for word in sentence.split())\n",
    "    ]\n",
    "\n",
    "\n",
    "def generate_sentences_lists():\n",
    "    valid_word_regex = re.compile(r'^[a-zA-ZÀ-ÿ]+$')\n",
    "    min_length, max_length = 5, 20\n",
    "    \n",
    "    french_example_sentences = []\n",
    "    english_example_sentences = []\n",
    "    \n",
    "    references_fr = r'RÉFÉRENCES CITÉES'.lower()\n",
    "    references_en = r'REFERENCES CITED'.lower()\n",
    "        \n",
    "    for i, row in lang_df.iterrows():\n",
    "        fr_path, en_path = get_filepaths(row)\n",
    "        \n",
    "        with open(fr_path, 'r', encoding='utf-8') as file:\n",
    "            fr_text = json.load(file).get('text', '').lower()\n",
    "            french_example_sentences.extend(process_sentences_list(fr_text, references_fr))\n",
    "        \n",
    "        with open(en_path, 'r', encoding='utf-8') as file:\n",
    "            en_text = json.load(file).get('text', '').lower()\n",
    "            english_example_sentences.extend(process_sentences_list(en_text, references_en))\n",
    "            \n",
    "    # clean messy sentences\n",
    "    margin_required = 1\n",
    "\n",
    "    french_example_sentences = [\n",
    "        sentence for sentence in french_example_sentences\n",
    "        if sum(1 for x in sentence.split() if x in fr_scrabble) > sum(1 for x in sentence.split() if x in en_scrabble) + margin_required\n",
    "    ]\n",
    "    \n",
    "    english_example_sentences = [\n",
    "        sentence for sentence in english_example_sentences\n",
    "        if sum(1 for x in sentence.split() if x in en_scrabble) > sum(1 for x in sentence.split() if x in fr_scrabble) + margin_required\n",
    "    ]\n",
    "        \n",
    "    return french_example_sentences, english_example_sentences\n"
   ],
   "id": "d61afdf21f22c367",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:58:18.473454Z",
     "start_time": "2025-01-31T16:58:15.155214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# generate example sentences for testing\n",
    "french_example_sentences, english_example_sentences = generate_sentences_lists()"
   ],
   "id": "221c462c3a65ce72",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:58:18.512220Z",
     "start_time": "2025-01-31T16:58:18.507758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# before scrabble cleaning\n",
    "len(french_example_sentences), len(english_example_sentences)"
   ],
   "id": "c56c37e6e3bd6248",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44271, 68556)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T17:10:14.596285Z",
     "start_time": "2025-01-31T17:10:03.060030Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35393, 66084)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67,
   "source": [
    "# after scrabble cleaning\n",
    "french_example_sentences, english_example_sentences = generate_sentences_lists()\n",
    "len(french_example_sentences), len(english_example_sentences)"
   ],
   "id": "fd12c3047e95de64"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "965c8f1cd7234a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T17:24:39.697713Z",
     "start_time": "2025-01-31T17:24:39.690746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_word_list(text, references_pattern):\n",
    "    valid_word_regex = re.compile(r'^[a-zA-ZÀ-ÿ]+$')\n",
    "    \n",
    "    document_parts = re.split(references_pattern, text, flags=re.IGNORECASE)\n",
    "    if 2 < len(document_parts) < 5:\n",
    "        text = document_parts[1]\n",
    "    word_list = [word for word in text.split() if valid_word_regex.match(word)]\n",
    "    \n",
    "    return word_list\n",
    "\n",
    "\n",
    "def generate_word_lists(n):\n",
    "    french_word_list = []\n",
    "    english_word_list = []\n",
    "    exclude_words_with_less_than_n = n\n",
    "    \n",
    "    references_fr = r'RÉFÉRENCES CITÉES'.lower()\n",
    "    references_en = r'REFERENCES CITED'.lower()\n",
    "        \n",
    "    for i, row in lang_df.iterrows():\n",
    "        fr_path, en_path = get_filepaths(row)\n",
    "        \n",
    "        with open(fr_path, 'r', encoding='utf-8') as file:\n",
    "            fr_text = json.load(file).get('text', '').lower()\n",
    "            french_word_list.extend(process_word_list(fr_text, references_fr))\n",
    "        \n",
    "        with open(en_path, 'r', encoding='utf-8') as file:\n",
    "            en_text = json.load(file).get('text', '').lower()\n",
    "            english_word_list.extend(process_word_list(en_text, references_en))\n",
    "    \n",
    "    \n",
    "    french_word_counts = Counter(french_word_list)\n",
    "    english_word_counts = Counter(english_word_list)\n",
    "            \n",
    "    french_word_list = [word for word, count in french_word_counts.items() if count >= exclude_words_with_less_than_n]\n",
    "    english_word_list = [word for word, count in english_word_counts.items() if count >= exclude_words_with_less_than_n]\n",
    "    \n",
    "    french_words = set(french_word_list)\n",
    "    english_words = set(english_word_list)\n",
    "    \n",
    "    french_word_list = remove_non_scrabble_words(french_word_list, fr_scrabble)\n",
    "    english_word_list = remove_non_scrabble_words(english_word_list, en_scrabble)\n",
    "    \n",
    "    overlapping_words = english_words & french_words\n",
    "    english_words.difference_update(overlapping_words)\n",
    "    french_words.difference_update(overlapping_words)\n",
    "    \n",
    "    english_words.difference_update({w for w in english_words if w.isnumeric()})\n",
    "    french_words.difference_update({w for w in french_words if w.isnumeric()})\n",
    "    \n",
    "    return english_words, french_words\n"
   ],
   "id": "7befe463c579211d",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T17:24:54.084539Z",
     "start_time": "2025-01-31T17:24:40.376746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for n in [0, 1, 10, 150, 1000]:\n",
    "    english_words, french_words = generate_word_lists(n)\n",
    "    print(len(english_words), len(french_words))"
   ],
   "id": "5e4712c247ff4f92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12395 18914\n",
      "12395 18914\n",
      "5618 7113\n",
      "1531 1517\n",
      "288 268\n"
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e46edcad9e4927de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "53f816ef08bf4fb2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ebe72b71e1cd2b2b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b6327720ee11b32"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "31863395234b17c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fbb388dbb7d04ece"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "187ca3473f57bcf5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "650bb99ef63fbe3a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T17:25:58.943472Z",
     "start_time": "2025-01-31T17:25:58.925457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_results(n_to_exclude, french_example_sentences_n, english_example_sentences_n):\n",
    "    results = []\n",
    "    \n",
    "    for n in n_to_exclude:\n",
    "        print(f'Processing {n}')\n",
    "        english_words, french_words = generate_word_lists(n)\n",
    "        \n",
    "        for sentence in french_example_sentences_n:\n",
    "            fr_count = sum(1 for word in sentence.split() if word in french_words)\n",
    "            en_count = sum(1 for word in sentence.split() if word in english_words)\n",
    "            results.append((n, 'fr', fr_count, en_count))\n",
    "        \n",
    "        for sentence in english_example_sentences_n:\n",
    "            fr_count = sum(1 for word in sentence.split() if word in french_words)\n",
    "            en_count = sum(1 for word in sentence.split() if word in english_words)\n",
    "            results.append((n, 'en', fr_count, en_count))\n",
    "        \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.columns = ['n_excluded', 'language', 'fr_count', 'en_count']\n",
    "    \n",
    "    results_df['total_count'] = results_df['fr_count'] + results_df['en_count']\n",
    "    \n",
    "    valid_mask = results_df['total_count'] > 0\n",
    "    \n",
    "    results_df['correct_count'] = np.where(\n",
    "        (results_df['language'] == 'fr') & valid_mask,\n",
    "        results_df['fr_count'],\n",
    "        np.where(\n",
    "            (results_df['language'] == 'en') & valid_mask,\n",
    "            results_df['en_count'],\n",
    "            0\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    results_df['wrong_count'] = np.where(\n",
    "        (results_df['language'] == 'fr') & valid_mask,\n",
    "        results_df['en_count'],\n",
    "        np.where(\n",
    "            (results_df['language'] == 'en') & valid_mask,\n",
    "            results_df['fr_count'],\n",
    "            0\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    results_df['is_correct'] = results_df['correct_count'] > results_df['wrong_count']\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "\n",
    "def create_stats(results_df):\n",
    "    \n",
    "    # Define FP & FN for each language\n",
    "    results_df['fr_false_positive'] = (results_df['language'] == 'en') & (results_df['is_correct'] == False)\n",
    "    results_df['fr_false_negative'] = (results_df['language'] == 'fr') & (results_df['is_correct'] == False)\n",
    "    results_df['en_false_positive'] = (results_df['language'] == 'fr') & (results_df['is_correct'] == False)\n",
    "    results_df['en_false_negative'] = (results_df['language'] == 'en') & (results_df['is_correct'] == False)\n",
    "    \n",
    "    # Compute separate aggregations\n",
    "    grouped_df = results_df.groupby('n_excluded').agg(\n",
    "        total_count=('is_correct', 'count'),  # count rows (not the same as results_df['total_count']\n",
    "        \n",
    "        # Correct and incorrect classifications\n",
    "        correct_count=('is_correct', 'sum'),\n",
    "        wrong_count=('is_correct', lambda x: (~x).sum()),  \n",
    "    \n",
    "        # False Positives & False Negatives for each language\n",
    "        fr_false_positive=('fr_false_positive', 'sum'),\n",
    "        fr_false_negative=('fr_false_negative', 'sum'),\n",
    "        en_false_positive=('en_false_positive', 'sum'),\n",
    "        en_false_negative=('en_false_negative', 'sum')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    valid_mask = grouped_df['total_count'] > 0\n",
    "    \n",
    "    # Accuracy (same for both languages)\n",
    "    grouped_df['accuracy'] = np.where(valid_mask, grouped_df['correct_count'] / grouped_df['total_count'], 0)\n",
    "    \n",
    "    # Precision & Recall for French\n",
    "    fr_precision_mask = (grouped_df['correct_count'] + grouped_df['fr_false_positive']) > 0\n",
    "    grouped_df['fr_precision'] = np.where(\n",
    "        fr_precision_mask, \n",
    "        grouped_df['correct_count'] / (grouped_df['correct_count'] + grouped_df['fr_false_positive']), \n",
    "        0\n",
    "    )\n",
    "    \n",
    "    fr_recall_mask = (grouped_df['correct_count'] + grouped_df['fr_false_negative']) > 0\n",
    "    grouped_df['fr_recall'] = np.where(\n",
    "        fr_recall_mask, \n",
    "        grouped_df['correct_count'] / (grouped_df['correct_count'] + grouped_df['fr_false_negative']), \n",
    "        0\n",
    "    )\n",
    "    \n",
    "    # Precision & Recall for English\n",
    "    en_precision_mask = (grouped_df['correct_count'] + grouped_df['en_false_positive']) > 0\n",
    "    grouped_df['en_precision'] = np.where(\n",
    "        en_precision_mask, \n",
    "        grouped_df['correct_count'] / (grouped_df['correct_count'] + grouped_df['en_false_positive']), \n",
    "        0\n",
    "    )\n",
    "    \n",
    "    en_recall_mask = (grouped_df['correct_count'] + grouped_df['en_false_negative']) > 0\n",
    "    grouped_df['en_recall'] = np.where(\n",
    "        en_recall_mask, \n",
    "        grouped_df['correct_count'] / (grouped_df['correct_count'] + grouped_df['en_false_negative']), \n",
    "        0\n",
    "    )\n",
    "    \n",
    "    # F1-scores\n",
    "    grouped_df['fr_f1_score'] = np.where(\n",
    "        (grouped_df['fr_precision'] + grouped_df['fr_recall']) > 0,\n",
    "        2 * (grouped_df['fr_precision'] * grouped_df['fr_recall']) / (grouped_df['fr_precision'] + grouped_df['fr_recall']),\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    grouped_df['en_f1_score'] = np.where(\n",
    "        (grouped_df['en_precision'] + grouped_df['en_recall']) > 0,\n",
    "        2 * (grouped_df['en_precision'] * grouped_df['en_recall']) / (grouped_df['en_precision'] + grouped_df['en_recall']),\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    grouped_df['stats_sum'] = grouped_df[['accuracy', 'fr_precision', 'fr_recall', 'en_precision', 'en_recall', 'fr_f1_score', 'en_f1_score']].sum(axis=1)\n",
    "    \n",
    "    return grouped_df\n"
   ],
   "id": "70f61e411eef989d",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T17:26:28.253269Z",
     "start_time": "2025-01-31T17:26:00.840936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_to_exclude = [0, 1, 5, 10, 20, 50, 100, 200, 500, 1000]\n",
    "n_trials = 100\n",
    "\n",
    "results_df = process_results(\n",
    "    n_to_exclude, \n",
    "    random.sample(french_example_sentences, n_trials), \n",
    "    random.sample(english_example_sentences, n_trials)\n",
    ")\n",
    "grouped_df = create_stats(results_df)"
   ],
   "id": "a0482b7130bd17fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0\n",
      "Processing 1\n",
      "Processing 5\n",
      "Processing 10\n",
      "Processing 20\n",
      "Processing 50\n",
      "Processing 100\n",
      "Processing 200\n",
      "Processing 500\n",
      "Processing 1000\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T17:26:28.573804Z",
     "start_time": "2025-01-31T17:26:28.566089Z"
    }
   },
   "cell_type": "code",
   "source": "grouped_df.set_index('n_excluded').T",
   "id": "cb44d9b835742b3f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n_excluded          0      1      5      10     20     50     100    200   \\\n",
       "total_count       200.00 200.00 200.00 200.00 200.00 200.00 200.00 200.00   \n",
       "correct_count     177.00 177.00 191.00 198.00 198.00 199.00 199.00 198.00   \n",
       "wrong_count        23.00  23.00   9.00   2.00   2.00   1.00   1.00   2.00   \n",
       "fr_false_positive  21.00  21.00   9.00   2.00   2.00   1.00   1.00   1.00   \n",
       "fr_false_negative   2.00   2.00   0.00   0.00   0.00   0.00   0.00   1.00   \n",
       "en_false_positive   2.00   2.00   0.00   0.00   0.00   0.00   0.00   1.00   \n",
       "en_false_negative  21.00  21.00   9.00   2.00   2.00   1.00   1.00   1.00   \n",
       "accuracy            0.89   0.89   0.95   0.99   0.99   0.99   0.99   0.99   \n",
       "fr_precision        0.89   0.89   0.95   0.99   0.99   0.99   0.99   0.99   \n",
       "fr_recall           0.99   0.99   1.00   1.00   1.00   1.00   1.00   0.99   \n",
       "en_precision        0.99   0.99   1.00   1.00   1.00   1.00   1.00   0.99   \n",
       "en_recall           0.89   0.89   0.95   0.99   0.99   0.99   0.99   0.99   \n",
       "fr_f1_score         0.94   0.94   0.98   0.99   0.99   1.00   1.00   0.99   \n",
       "en_f1_score         0.94   0.94   0.98   0.99   0.99   1.00   1.00   0.99   \n",
       "stats_sum           6.53   6.53   6.82   6.96   6.96   6.98   6.98   6.96   \n",
       "\n",
       "n_excluded          500    1000  \n",
       "total_count       200.00 200.00  \n",
       "correct_count     198.00 196.00  \n",
       "wrong_count         2.00   4.00  \n",
       "fr_false_positive   1.00   3.00  \n",
       "fr_false_negative   1.00   1.00  \n",
       "en_false_positive   1.00   1.00  \n",
       "en_false_negative   1.00   3.00  \n",
       "accuracy            0.99   0.98  \n",
       "fr_precision        0.99   0.98  \n",
       "fr_recall           0.99   0.99  \n",
       "en_precision        0.99   0.99  \n",
       "en_recall           0.99   0.98  \n",
       "fr_f1_score         0.99   0.99  \n",
       "en_f1_score         0.99   0.99  \n",
       "stats_sum           6.96   6.92  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>n_excluded</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "      <th>50</th>\n",
       "      <th>100</th>\n",
       "      <th>200</th>\n",
       "      <th>500</th>\n",
       "      <th>1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_count</th>\n",
       "      <td>200.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correct_count</th>\n",
       "      <td>177.00</td>\n",
       "      <td>177.00</td>\n",
       "      <td>191.00</td>\n",
       "      <td>198.00</td>\n",
       "      <td>198.00</td>\n",
       "      <td>199.00</td>\n",
       "      <td>199.00</td>\n",
       "      <td>198.00</td>\n",
       "      <td>198.00</td>\n",
       "      <td>196.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrong_count</th>\n",
       "      <td>23.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_false_positive</th>\n",
       "      <td>21.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_false_negative</th>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en_false_positive</th>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en_false_negative</th>\n",
       "      <td>21.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_precision</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_recall</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en_precision</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en_recall</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_f1_score</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en_f1_score</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_sum</th>\n",
       "      <td>6.53</td>\n",
       "      <td>6.53</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.96</td>\n",
       "      <td>6.96</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.96</td>\n",
       "      <td>6.96</td>\n",
       "      <td>6.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T17:26:43.673606Z",
     "start_time": "2025-01-31T17:26:43.662768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# all stats added together\n",
    "grouped_df.set_index('n_excluded')['stats_sum']"
   ],
   "id": "269c750da1846626",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n_excluded\n",
       "0      6.53\n",
       "1      6.53\n",
       "5      6.82\n",
       "10     6.96\n",
       "20     6.96\n",
       "50     6.98\n",
       "100    6.98\n",
       "200    6.96\n",
       "500    6.96\n",
       "1000   6.92\n",
       "Name: stats_sum, dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T17:27:27.626298Z",
     "start_time": "2025-01-31T17:27:27.612047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# backup old dfs\n",
    "results_df_BACKUP = results_df.copy() \n",
    "grouped_df_BACKUP = grouped_df.copy() "
   ],
   "id": "36cb01715f31204d",
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T17:31:01.741285Z",
     "start_time": "2025-01-31T17:29:26.129392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check from 10 to 500 in more detail\n",
    "n_to_exclude = [x for x in range(10, 200, 10)] + [x for x in range(200, 520, 20)]\n",
    "n_trials = 1000\n",
    "\n",
    "results_df = process_results(\n",
    "    n_to_exclude, \n",
    "    random.sample(french_example_sentences, n_trials), \n",
    "    random.sample(english_example_sentences, n_trials)\n",
    ")\n",
    "grouped_df = create_stats(results_df)"
   ],
   "id": "ba47a7f465f97437",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10\n",
      "Processing 20\n",
      "Processing 30\n",
      "Processing 40\n",
      "Processing 50\n",
      "Processing 60\n",
      "Processing 70\n",
      "Processing 80\n",
      "Processing 90\n",
      "Processing 100\n",
      "Processing 110\n",
      "Processing 120\n",
      "Processing 130\n",
      "Processing 140\n",
      "Processing 150\n",
      "Processing 160\n",
      "Processing 170\n",
      "Processing 180\n",
      "Processing 190\n",
      "Processing 200\n",
      "Processing 220\n",
      "Processing 240\n",
      "Processing 260\n",
      "Processing 280\n",
      "Processing 300\n",
      "Processing 320\n",
      "Processing 340\n",
      "Processing 360\n",
      "Processing 380\n",
      "Processing 400\n",
      "Processing 420\n",
      "Processing 440\n",
      "Processing 460\n",
      "Processing 480\n",
      "Processing 500\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T17:31:01.768024Z",
     "start_time": "2025-01-31T17:31:01.742794Z"
    }
   },
   "cell_type": "code",
   "source": "grouped_df.set_index('n_excluded').T",
   "id": "7ef88cd1369058c4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n_excluded            10      20      30      40      50      60      70   \\\n",
       "total_count       2000.00 2000.00 2000.00 2000.00 2000.00 2000.00 2000.00   \n",
       "correct_count     1938.00 1965.00 1973.00 1977.00 1987.00 1988.00 1990.00   \n",
       "wrong_count         62.00   35.00   27.00   23.00   13.00   12.00   10.00   \n",
       "fr_false_positive   52.00   34.00   25.00   22.00   12.00   10.00    8.00   \n",
       "fr_false_negative   10.00    1.00    2.00    1.00    1.00    2.00    2.00   \n",
       "en_false_positive   10.00    1.00    2.00    1.00    1.00    2.00    2.00   \n",
       "en_false_negative   52.00   34.00   25.00   22.00   12.00   10.00    8.00   \n",
       "accuracy             0.97    0.98    0.99    0.99    0.99    0.99    0.99   \n",
       "fr_precision         0.97    0.98    0.99    0.99    0.99    0.99    1.00   \n",
       "fr_recall            0.99    1.00    1.00    1.00    1.00    1.00    1.00   \n",
       "en_precision         0.99    1.00    1.00    1.00    1.00    1.00    1.00   \n",
       "en_recall            0.97    0.98    0.99    0.99    0.99    0.99    1.00   \n",
       "fr_f1_score          0.98    0.99    0.99    0.99    1.00    1.00    1.00   \n",
       "en_f1_score          0.98    0.99    0.99    0.99    1.00    1.00    1.00   \n",
       "stats_sum            6.87    6.93    6.95    6.95    6.97    6.98    6.98   \n",
       "\n",
       "n_excluded            80      90      100     110     120     130     140  \\\n",
       "total_count       2000.00 2000.00 2000.00 2000.00 2000.00 2000.00 2000.00   \n",
       "correct_count     1988.00 1989.00 1993.00 1992.00 1992.00 1992.00 1994.00   \n",
       "wrong_count         12.00   11.00    7.00    8.00    8.00    8.00    6.00   \n",
       "fr_false_positive   10.00    9.00    5.00    6.00    7.00    7.00    5.00   \n",
       "fr_false_negative    2.00    2.00    2.00    2.00    1.00    1.00    1.00   \n",
       "en_false_positive    2.00    2.00    2.00    2.00    1.00    1.00    1.00   \n",
       "en_false_negative   10.00    9.00    5.00    6.00    7.00    7.00    5.00   \n",
       "accuracy             0.99    0.99    1.00    1.00    1.00    1.00    1.00   \n",
       "fr_precision         0.99    1.00    1.00    1.00    1.00    1.00    1.00   \n",
       "fr_recall            1.00    1.00    1.00    1.00    1.00    1.00    1.00   \n",
       "en_precision         1.00    1.00    1.00    1.00    1.00    1.00    1.00   \n",
       "en_recall            0.99    1.00    1.00    1.00    1.00    1.00    1.00   \n",
       "fr_f1_score          1.00    1.00    1.00    1.00    1.00    1.00    1.00   \n",
       "en_f1_score          1.00    1.00    1.00    1.00    1.00    1.00    1.00   \n",
       "stats_sum            6.98    6.98    6.99    6.98    6.98    6.98    6.99   \n",
       "\n",
       "n_excluded            150     160     170     180     190     200     220  \\\n",
       "total_count       2000.00 2000.00 2000.00 2000.00 2000.00 2000.00 2000.00   \n",
       "correct_count     1994.00 1996.00 1998.00 1991.00 1991.00 1991.00 1989.00   \n",
       "wrong_count          6.00    4.00    2.00    9.00    9.00    9.00   11.00   \n",
       "fr_false_positive    5.00    3.00    1.00    8.00    8.00    8.00   10.00   \n",
       "fr_false_negative    1.00    1.00    1.00    1.00    1.00    1.00    1.00   \n",
       "en_false_positive    1.00    1.00    1.00    1.00    1.00    1.00    1.00   \n",
       "en_false_negative    5.00    3.00    1.00    8.00    8.00    8.00   10.00   \n",
       "accuracy             1.00    1.00    1.00    1.00    1.00    1.00    0.99   \n",
       "fr_precision         1.00    1.00    1.00    1.00    1.00    1.00    0.99   \n",
       "fr_recall            1.00    1.00    1.00    1.00    1.00    1.00    1.00   \n",
       "en_precision         1.00    1.00    1.00    1.00    1.00    1.00    1.00   \n",
       "en_recall            1.00    1.00    1.00    1.00    1.00    1.00    0.99   \n",
       "fr_f1_score          1.00    1.00    1.00    1.00    1.00    1.00    1.00   \n",
       "en_f1_score          1.00    1.00    1.00    1.00    1.00    1.00    1.00   \n",
       "stats_sum            6.99    6.99    7.00    6.98    6.98    6.98    6.98   \n",
       "\n",
       "n_excluded            240     260     280     300     320     340     360  \\\n",
       "total_count       2000.00 2000.00 2000.00 2000.00 2000.00 2000.00 2000.00   \n",
       "correct_count     1987.00 1986.00 1985.00 1983.00 1983.00 1979.00 1979.00   \n",
       "wrong_count         13.00   14.00   15.00   17.00   17.00   21.00   21.00   \n",
       "fr_false_positive   12.00   13.00   13.00   15.00   15.00   20.00   20.00   \n",
       "fr_false_negative    1.00    1.00    2.00    2.00    2.00    1.00    1.00   \n",
       "en_false_positive    1.00    1.00    2.00    2.00    2.00    1.00    1.00   \n",
       "en_false_negative   12.00   13.00   13.00   15.00   15.00   20.00   20.00   \n",
       "accuracy             0.99    0.99    0.99    0.99    0.99    0.99    0.99   \n",
       "fr_precision         0.99    0.99    0.99    0.99    0.99    0.99    0.99   \n",
       "fr_recall            1.00    1.00    1.00    1.00    1.00    1.00    1.00   \n",
       "en_precision         1.00    1.00    1.00    1.00    1.00    1.00    1.00   \n",
       "en_recall            0.99    0.99    0.99    0.99    0.99    0.99    0.99   \n",
       "fr_f1_score          1.00    1.00    1.00    1.00    1.00    0.99    0.99   \n",
       "en_f1_score          1.00    1.00    1.00    1.00    1.00    0.99    0.99   \n",
       "stats_sum            6.97    6.97    6.97    6.97    6.97    6.96    6.96   \n",
       "\n",
       "n_excluded            380     400     420     440     460     480     500  \n",
       "total_count       2000.00 2000.00 2000.00 2000.00 2000.00 2000.00 2000.00  \n",
       "correct_count     1980.00 1978.00 1977.00 1977.00 1978.00 1978.00 1979.00  \n",
       "wrong_count         20.00   22.00   23.00   23.00   22.00   22.00   21.00  \n",
       "fr_false_positive   19.00   20.00   21.00   21.00   20.00   20.00   18.00  \n",
       "fr_false_negative    1.00    2.00    2.00    2.00    2.00    2.00    3.00  \n",
       "en_false_positive    1.00    2.00    2.00    2.00    2.00    2.00    3.00  \n",
       "en_false_negative   19.00   20.00   21.00   21.00   20.00   20.00   18.00  \n",
       "accuracy             0.99    0.99    0.99    0.99    0.99    0.99    0.99  \n",
       "fr_precision         0.99    0.99    0.99    0.99    0.99    0.99    0.99  \n",
       "fr_recall            1.00    1.00    1.00    1.00    1.00    1.00    1.00  \n",
       "en_precision         1.00    1.00    1.00    1.00    1.00    1.00    1.00  \n",
       "en_recall            0.99    0.99    0.99    0.99    0.99    0.99    0.99  \n",
       "fr_f1_score          0.99    0.99    0.99    0.99    0.99    0.99    0.99  \n",
       "en_f1_score          0.99    0.99    0.99    0.99    0.99    0.99    0.99  \n",
       "stats_sum            6.96    6.96    6.95    6.95    6.96    6.96    6.96  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>n_excluded</th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "      <th>30</th>\n",
       "      <th>40</th>\n",
       "      <th>50</th>\n",
       "      <th>60</th>\n",
       "      <th>70</th>\n",
       "      <th>80</th>\n",
       "      <th>90</th>\n",
       "      <th>100</th>\n",
       "      <th>110</th>\n",
       "      <th>120</th>\n",
       "      <th>130</th>\n",
       "      <th>140</th>\n",
       "      <th>150</th>\n",
       "      <th>160</th>\n",
       "      <th>170</th>\n",
       "      <th>180</th>\n",
       "      <th>190</th>\n",
       "      <th>200</th>\n",
       "      <th>220</th>\n",
       "      <th>240</th>\n",
       "      <th>260</th>\n",
       "      <th>280</th>\n",
       "      <th>300</th>\n",
       "      <th>320</th>\n",
       "      <th>340</th>\n",
       "      <th>360</th>\n",
       "      <th>380</th>\n",
       "      <th>400</th>\n",
       "      <th>420</th>\n",
       "      <th>440</th>\n",
       "      <th>460</th>\n",
       "      <th>480</th>\n",
       "      <th>500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_count</th>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correct_count</th>\n",
       "      <td>1938.00</td>\n",
       "      <td>1965.00</td>\n",
       "      <td>1973.00</td>\n",
       "      <td>1977.00</td>\n",
       "      <td>1987.00</td>\n",
       "      <td>1988.00</td>\n",
       "      <td>1990.00</td>\n",
       "      <td>1988.00</td>\n",
       "      <td>1989.00</td>\n",
       "      <td>1993.00</td>\n",
       "      <td>1992.00</td>\n",
       "      <td>1992.00</td>\n",
       "      <td>1992.00</td>\n",
       "      <td>1994.00</td>\n",
       "      <td>1994.00</td>\n",
       "      <td>1996.00</td>\n",
       "      <td>1998.00</td>\n",
       "      <td>1991.00</td>\n",
       "      <td>1991.00</td>\n",
       "      <td>1991.00</td>\n",
       "      <td>1989.00</td>\n",
       "      <td>1987.00</td>\n",
       "      <td>1986.00</td>\n",
       "      <td>1985.00</td>\n",
       "      <td>1983.00</td>\n",
       "      <td>1983.00</td>\n",
       "      <td>1979.00</td>\n",
       "      <td>1979.00</td>\n",
       "      <td>1980.00</td>\n",
       "      <td>1978.00</td>\n",
       "      <td>1977.00</td>\n",
       "      <td>1977.00</td>\n",
       "      <td>1978.00</td>\n",
       "      <td>1978.00</td>\n",
       "      <td>1979.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrong_count</th>\n",
       "      <td>62.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>27.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>21.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_false_positive</th>\n",
       "      <td>52.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_false_negative</th>\n",
       "      <td>10.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en_false_positive</th>\n",
       "      <td>10.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en_false_negative</th>\n",
       "      <td>52.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_precision</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_recall</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en_precision</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en_recall</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_f1_score</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en_f1_score</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_sum</th>\n",
       "      <td>6.87</td>\n",
       "      <td>6.93</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.97</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.99</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.99</td>\n",
       "      <td>6.99</td>\n",
       "      <td>6.99</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.97</td>\n",
       "      <td>6.97</td>\n",
       "      <td>6.97</td>\n",
       "      <td>6.97</td>\n",
       "      <td>6.97</td>\n",
       "      <td>6.96</td>\n",
       "      <td>6.96</td>\n",
       "      <td>6.96</td>\n",
       "      <td>6.96</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.96</td>\n",
       "      <td>6.96</td>\n",
       "      <td>6.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T17:31:02.040310Z",
     "start_time": "2025-01-31T17:31:02.034033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# all stats added together\n",
    "grouped_df.set_index('n_excluded')['stats_sum']"
   ],
   "id": "b278789fc3d6193a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n_excluded\n",
       "10    6.87\n",
       "20    6.93\n",
       "30    6.95\n",
       "40    6.95\n",
       "50    6.97\n",
       "60    6.98\n",
       "70    6.98\n",
       "80    6.98\n",
       "90    6.98\n",
       "100   6.99\n",
       "110   6.98\n",
       "120   6.98\n",
       "130   6.98\n",
       "140   6.99\n",
       "150   6.99\n",
       "160   6.99\n",
       "170   7.00\n",
       "180   6.98\n",
       "190   6.98\n",
       "200   6.98\n",
       "220   6.98\n",
       "240   6.97\n",
       "260   6.97\n",
       "280   6.97\n",
       "300   6.97\n",
       "320   6.97\n",
       "340   6.96\n",
       "360   6.96\n",
       "380   6.96\n",
       "400   6.96\n",
       "420   6.95\n",
       "440   6.95\n",
       "460   6.96\n",
       "480   6.96\n",
       "500   6.96\n",
       "Name: stats_sum, dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 170 looks best, confirm with a bigger sample and tighter hyperparameters ",
   "id": "13df8f7ce78f5ae5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T17:37:39.239886Z",
     "start_time": "2025-01-31T17:36:33.040705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_to_exclude = [x for x in range(100, 205, 5)]\n",
    "n_trials = 5000\n",
    "\n",
    "results_df = process_results(\n",
    "    n_to_exclude, \n",
    "    random.sample(french_example_sentences, n_trials), \n",
    "    random.sample(english_example_sentences, n_trials)\n",
    ")\n",
    "grouped_df = create_stats(results_df)\n",
    "grouped_df.set_index('n_excluded')['stats_sum']"
   ],
   "id": "931df46ae01aca51",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 100\n",
      "Processing 105\n",
      "Processing 110\n",
      "Processing 115\n",
      "Processing 120\n",
      "Processing 125\n",
      "Processing 130\n",
      "Processing 135\n",
      "Processing 140\n",
      "Processing 145\n",
      "Processing 150\n",
      "Processing 155\n",
      "Processing 160\n",
      "Processing 165\n",
      "Processing 170\n",
      "Processing 175\n",
      "Processing 180\n",
      "Processing 185\n",
      "Processing 190\n",
      "Processing 195\n",
      "Processing 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "n_excluded\n",
       "100   6.97\n",
       "105   6.97\n",
       "110   6.97\n",
       "115   6.98\n",
       "120   6.98\n",
       "125   6.98\n",
       "130   6.98\n",
       "135   6.98\n",
       "140   6.98\n",
       "145   6.98\n",
       "150   6.98\n",
       "155   6.98\n",
       "160   6.98\n",
       "165   6.98\n",
       "170   6.98\n",
       "175   6.97\n",
       "180   6.97\n",
       "185   6.97\n",
       "190   6.97\n",
       "195   6.97\n",
       "200   6.97\n",
       "Name: stats_sum, dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T17:40:14.446206Z",
     "start_time": "2025-01-31T17:39:35.408150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# looks like anything between 115 and 170 is good... try once more with more sig figs and more trials\n",
    "n_to_exclude = [x for x in range(110, 180, 5)]\n",
    "n_trials = 10000\n",
    "\n",
    "results_df = process_results(\n",
    "    n_to_exclude, \n",
    "    random.sample(french_example_sentences, n_trials), \n",
    "    random.sample(english_example_sentences, n_trials)\n",
    ")\n",
    "grouped_df = create_stats(results_df)\n",
    "grouped_df.set_index('n_excluded')['stats_sum']"
   ],
   "id": "f0fc37c54d67bf95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 110\n",
      "Processing 115\n",
      "Processing 120\n",
      "Processing 125\n",
      "Processing 130\n",
      "Processing 135\n",
      "Processing 140\n",
      "Processing 145\n",
      "Processing 150\n",
      "Processing 155\n",
      "Processing 160\n",
      "Processing 165\n",
      "Processing 170\n",
      "Processing 175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "n_excluded\n",
       "110   6.979\n",
       "115   6.981\n",
       "120   6.982\n",
       "125   6.982\n",
       "130   6.984\n",
       "135   6.984\n",
       "140   6.984\n",
       "145   6.985\n",
       "150   6.984\n",
       "155   6.985\n",
       "160   6.982\n",
       "165   6.980\n",
       "170   6.982\n",
       "175   6.973\n",
       "Name: stats_sum, dtype: float64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# best answers centre around 150, but results are very similar. choose 150 arbitrarily because it is the 'roundest' number",
   "id": "4143925f29054491"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Save Data For Classifier",
   "id": "413fb2ce54ceac84"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T17:42:07.830533Z",
     "start_time": "2025-01-31T17:42:05.014580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "english_words, french_words = generate_word_lists(150)\n",
    "\n",
    "# save optimised word lists \n",
    "with open(\"language_classifier/wordlists.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"en\": list(english_words), \"fr\": list(french_words)}, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "# save 10k sentences per language for testing\n",
    "with open(\"language_classifier/example_sentences.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"en\": english_example_sentences, \"fr\": french_example_sentences}, f, ensure_ascii=False, indent=4)"
   ],
   "id": "b92f2debd2a73216",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T15:08:18.475559Z",
     "start_time": "2025-01-31T15:08:18.472706Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "408b7351a871791a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T15:08:18.486171Z",
     "start_time": "2025-01-31T15:08:18.475559Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2b4f1918d4be6fbf",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
