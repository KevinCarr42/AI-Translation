{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-03T18:09:51.806530Z",
     "start_time": "2025-02-03T18:09:51.273841Z"
    }
   },
   "source": [
    "import difflib\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from language_classifier.language_classifier import LanguageClassifier\n",
    "clf = LanguageClassifier()\n",
    "\n",
    "# formatting\n",
    "pd.set_option('display.float_format', '{:.1f}'.format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', 200)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# import data",
   "id": "a9aae87a2e850e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T18:09:51.892620Z",
     "start_time": "2025-02-03T18:09:51.816119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# folders\n",
    "parsed_docs_folder = os.path.join(\"..\", \"ParsedPublications\")\n",
    "fr_eng_correlation_csv = \"fr_eng_correlation_data.csv\"\n",
    "\n",
    "fr_eng_correlation_df = pd.read_csv(fr_eng_correlation_csv)\n",
    "\n",
    "# weblinks for previewing / testing\n",
    "weblinks_df = fr_eng_correlation_df.copy()\n",
    "weblinks_df = weblinks_df[['pub_number', 'nom', 'name', 'url_fr', 'url_en', 'file_url_fr', 'file_url_en']]\n",
    "\n",
    "# simplified correlation table\n",
    "fr_eng_correlation_df = fr_eng_correlation_df[['pub_number', 'filename_fr', 'filename_en']]"
   ],
   "id": "83675b54298a8486",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# helper functions",
   "id": "ca8dc9ee3a7f7d60"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T18:09:52.455697Z",
     "start_time": "2025-02-03T18:09:52.450581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preview_publication(pub_number):\n",
    "    if type(pub_number) is pd.DataFrame and pub_number.shape[0] == 1:\n",
    "        try:\n",
    "            pub_number = pub_number['pub_number'].values[0]\n",
    "        except ValueError:\n",
    "            return None\n",
    "    elif type(pub_number) is pd.Series:\n",
    "        try:\n",
    "            pub_number = pub_number.values[0]\n",
    "        except ValueError:\n",
    "            return None\n",
    "    \n",
    "    try:\n",
    "        output_df = weblinks_df[weblinks_df.pub_number == pub_number].T\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "        \n",
    "    return output_df\n"
   ],
   "id": "93d13f552b93b1a0",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T18:10:13.950405Z",
     "start_time": "2025-02-03T18:10:13.932564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DATA CLEANING FUNCTIONS\n",
    "\n",
    "\n",
    "def get_files_for_publication(pub_number, fr_eng_correlation_df):\n",
    "    row = fr_eng_correlation_df.loc[fr_eng_correlation_df['pub_number'] == pub_number]\n",
    "    if not row.empty:\n",
    "        filename_fr = row['filename_fr'].values[0]\n",
    "        filename_en = row['filename_en'].values[0]\n",
    "        return filename_fr, filename_en\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def get_json_file_link(parsed_docs_folder, pdf_filename):\n",
    "    if pdf_filename.endswith(\".pdf\"):\n",
    "        json_filename = pdf_filename + \".json\"\n",
    "        for root, _, files in os.walk(parsed_docs_folder):\n",
    "            if json_filename in files:\n",
    "                return os.path.join(root, json_filename)\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_text_from_single_file(json_file, target_language):\n",
    "    with open(json_file, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    if 'text' not in data:\n",
    "        raise KeyError(f\"The key 'text' is missing in the JSON file: {json_file}\")\n",
    "    \n",
    "    full_text = data['text']\n",
    "    text_blocks = re.split(r'[.\\n?]', full_text)\n",
    "    text = []\n",
    "\n",
    "    for block in text_blocks:\n",
    "        block = block.strip()\n",
    "        if not block:\n",
    "            continue\n",
    "            \n",
    "        if clf.classify(block) == target_language:\n",
    "            text.append(block)        \n",
    "\n",
    "    return \" \".join(text)\n",
    "\n",
    "\n",
    "\n",
    "def extract_both_languages_from_two_files(json_file_fr, json_file_en):\n",
    "    return extract_text_from_single_file(json_file_fr, \"fr\"), extract_text_from_single_file(json_file_fr, \"en\")\n",
    "\n",
    "\n",
    "def extract_both_languages_from_single_file(json_file):\n",
    "    with open(json_file, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    if 'text' not in data:\n",
    "        raise KeyError(f\"The key 'text' is missing in the JSON file: {json_file}\")\n",
    "    \n",
    "    full_text = data['text']\n",
    "    text_blocks = re.split(r'[.\\n?]', full_text)\n",
    "    text_fr, text_en = [], []\n",
    "\n",
    "    for block in text_blocks:\n",
    "        block = block.strip()\n",
    "        if not block:\n",
    "            continue\n",
    "            \n",
    "        if clf.classify(block) == \"fr\":\n",
    "            text_fr.append(block)   \n",
    "        elif clf.classify(block) == \"en\":\n",
    "            text_en.append(block)   \n",
    "\n",
    "    return \" \".join(text_fr), \" \".join(text_en)\n",
    "\n",
    "\n",
    "def correlate_and_clean_text(text_fr, text_en):\n",
    "    matcher = difflib.SequenceMatcher(None, text_fr.split(), text_en.split())\n",
    "    matched_fr, matched_en = [], []\n",
    "    \n",
    "    for tag, i1, i2, j1, j2 in matcher.get_opcodes():\n",
    "        if tag == 'equal':\n",
    "            matched_fr.append(\" \".join(text_fr.split()[i1:i2]))\n",
    "            matched_en.append(\" \".join(text_en.split()[j1:j2]))\n",
    "    \n",
    "    return matched_fr, matched_en\n",
    "\n",
    "\n",
    "def process_all_rows(fr_eng_correlation_df, parsed_docs_folder):\n",
    "    matched_data = []\n",
    "    min_text_quality = 1\n",
    "    \n",
    "    for _, row in fr_eng_correlation_df.iterrows():\n",
    "        pub_number = row['pub_number']\n",
    "        filename_fr, filename_en = row['filename_fr'], row['filename_en']\n",
    "        \n",
    "        if filename_fr == \"WITHDRAWN\" and filename_en == \"WITHDRAWN\":\n",
    "            continue\n",
    "        \n",
    "        json_file_fr = get_json_file_link(parsed_docs_folder, filename_fr)\n",
    "        json_file_en = get_json_file_link(parsed_docs_folder, filename_en)\n",
    "        \n",
    "        if filename_fr != filename_en:\n",
    "            text_fr, text_en = extract_both_languages_from_two_files(json_file_fr, json_file_en)\n",
    "        else:\n",
    "            text_fr, text_en = extract_both_languages_from_single_file(json_file_fr)\n",
    "        \n",
    "        matched_fr, matched_en = correlate_and_clean_text(text_fr, text_en)\n",
    "        matched_data.append({'pub_number': pub_number, 'text_fr': matched_fr, 'text_en': matched_en})\n",
    "    \n",
    "    return pd.DataFrame(matched_data)\n",
    "\n"
   ],
   "id": "2677bfe14b892d1e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T18:10:15.087483Z",
     "start_time": "2025-02-03T18:10:14.418526Z"
    }
   },
   "cell_type": "code",
   "source": "matched_df = process_all_rows(fr_eng_correlation_df, parsed_docs_folder)",
   "id": "1fda27a459b4f4ab",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'english_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m matched_df \u001B[38;5;241m=\u001B[39m \u001B[43mprocess_all_rows\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfr_eng_correlation_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparsed_docs_folder\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[6], line 105\u001B[0m, in \u001B[0;36mprocess_all_rows\u001B[1;34m(fr_eng_correlation_df, parsed_docs_folder)\u001B[0m\n\u001B[0;32m    103\u001B[0m     text_fr, text_en \u001B[38;5;241m=\u001B[39m extract_both_languages_from_two_files(json_file_fr, json_file_en)\n\u001B[0;32m    104\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 105\u001B[0m     text_fr, text_en \u001B[38;5;241m=\u001B[39m \u001B[43mextract_both_languages_from_single_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjson_file_fr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    107\u001B[0m matched_fr, matched_en \u001B[38;5;241m=\u001B[39m correlate_and_clean_text(text_fr, text_en)\n\u001B[0;32m    108\u001B[0m matched_data\u001B[38;5;241m.\u001B[39mappend({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpub_number\u001B[39m\u001B[38;5;124m'\u001B[39m: pub_number, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext_fr\u001B[39m\u001B[38;5;124m'\u001B[39m: matched_fr, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext_en\u001B[39m\u001B[38;5;124m'\u001B[39m: matched_en})\n",
      "Cell \u001B[1;32mIn[6], line 65\u001B[0m, in \u001B[0;36mextract_both_languages_from_single_file\u001B[1;34m(json_file)\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m block:\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m---> 65\u001B[0m en_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msum\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mword\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mblock\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mword\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43menglish_words\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     66\u001B[0m fr_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m block \u001B[38;5;28;01mif\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m french_words)\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fr_count \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m min_words_in_language \u001B[38;5;129;01mand\u001B[39;00m en_count \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m max_words_in_other_language:\n",
      "Cell \u001B[1;32mIn[6], line 65\u001B[0m, in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m block:\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m---> 65\u001B[0m en_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m block \u001B[38;5;28;01mif\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m \u001B[43menglish_words\u001B[49m)\n\u001B[0;32m     66\u001B[0m fr_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m block \u001B[38;5;28;01mif\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m french_words)\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fr_count \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m min_words_in_language \u001B[38;5;129;01mand\u001B[39;00m en_count \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m max_words_in_other_language:\n",
      "\u001B[1;31mNameError\u001B[0m: name 'english_words' is not defined"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b2fa3a609d06d204"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "84ec45563dbf8bad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7cf8c65a95b550cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "94b21f2e73ef52a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bcd611e20dc40c7e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
