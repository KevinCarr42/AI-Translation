{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-18T19:39:34.710074Z",
     "start_time": "2025-02-18T19:39:10.634199Z"
    }
   },
   "source": [
    "import difflib\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from alive_progress import alive_bar\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from language_classifier.language_classifier import LanguageClassifier\n",
    "\n",
    "# formatting\n",
    "pd.set_option('display.float_format', '{:.1f}'.format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# import data",
   "id": "a9aae87a2e850e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T19:39:34.802850Z",
     "start_time": "2025-02-18T19:39:34.713616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# folders\n",
    "parsed_docs_folder = os.path.join(\"..\", \"ParsedPublications\")\n",
    "fr_eng_correlation_csv = \"fr_eng_correlation_data.csv\"\n",
    "\n",
    "fr_eng_correlation_df = pd.read_csv(fr_eng_correlation_csv)\n",
    "\n",
    "# weblinks for previewing / testing\n",
    "weblinks_df = fr_eng_correlation_df.copy()\n",
    "weblinks_df = weblinks_df[['pub_number', 'nom', 'name', 'url_fr', 'url_en', 'file_url_fr', 'file_url_en']]\n",
    "\n",
    "# simplified correlation table\n",
    "fr_eng_correlation_df = fr_eng_correlation_df[['pub_number', 'filename_fr', 'filename_en']]"
   ],
   "id": "83675b54298a8486",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# functions",
   "id": "ca8dc9ee3a7f7d60"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T19:39:35.380254Z",
     "start_time": "2025-02-18T19:39:35.366796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DATA CLEANING FUNCTIONS\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    allowed_chars = r\"[^a-zA-ZÀ-ÖØ-öø-ÿ.,;:!?()'\\\"-]\"\n",
    "    text = re.sub(allowed_chars, ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_files_for_publication(pub_number, fr_eng_correlation_df):\n",
    "    row = fr_eng_correlation_df.loc[fr_eng_correlation_df['pub_number'] == pub_number]\n",
    "    if not row.empty:\n",
    "        filename_fr = row['filename_fr'].values[0]\n",
    "        filename_en = row['filename_en'].values[0]\n",
    "        return filename_fr, filename_en\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def get_json_file_link(parsed_docs_folder, pdf_filename):\n",
    "    if pdf_filename.endswith(\".pdf\"):\n",
    "        json_filename = pdf_filename + \".json\"\n",
    "        for root, _, files in os.walk(parsed_docs_folder):\n",
    "            if json_filename in files:\n",
    "                return os.path.join(root, json_filename)\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_text_from_single_file(json_file, target_language, clf):\n",
    "    min_block_length = 10\n",
    "    max_block_length = 500\n",
    "    \n",
    "    with open(json_file, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    if 'text' not in data:\n",
    "        raise KeyError(f\"The key 'text' is missing in the JSON file: {json_file}\")\n",
    "    \n",
    "    full_text = clean_text(data['text'])\n",
    "    text_blocks = re.split(r'(?<![;,])[.?!]\\s|\\n\\n', full_text)\n",
    "    text = []\n",
    "\n",
    "    for block in text_blocks:\n",
    "        block = block.strip()\n",
    "        if len(block) < min_block_length or len(block) > max_block_length:\n",
    "            continue\n",
    "        \n",
    "        if clf.classify(block) == target_language:\n",
    "            text.append(block + '. ')      \n",
    "\n",
    "    return \" \".join(text)\n",
    "\n",
    "\n",
    "def extract_both_languages_from_two_files(json_file_fr, json_file_en, clf):\n",
    "    return extract_text_from_single_file(json_file_fr, \"fr\", clf), extract_text_from_single_file(json_file_en, \"en\", clf)\n",
    "\n",
    "\n",
    "def extract_both_languages_from_single_file(json_file, clf):\n",
    "    min_block_length = 10\n",
    "    max_block_length = 500\n",
    "    \n",
    "    with open(json_file, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    if 'text' not in data:\n",
    "        raise KeyError(f\"The key 'text' is missing in the JSON file: {json_file}\")\n",
    "    \n",
    "    full_text = data['text']\n",
    "    text_blocks = re.split(r'(?<![;,])[.?!]\\s|\\n\\n', full_text)\n",
    "    text_fr, text_en = [], []\n",
    "\n",
    "    for block in text_blocks:\n",
    "        block = block.strip()\n",
    "        if len(block) < min_block_length or len(block) > max_block_length:\n",
    "            continue\n",
    "            \n",
    "        if clf.classify(block) == \"fr\":\n",
    "            text_fr.append(block + '. ')   \n",
    "        elif clf.classify(block) == \"en\":\n",
    "            text_en.append(block + '. ')   \n",
    "\n",
    "    return \" \".join(text_fr), \" \".join(text_en)\n",
    "\n",
    "\n",
    "def create_sentences(text_fr, text_en):\n",
    "    sentences_fr = [x.strip() for x in re.split(r'(?<![;,])[.?!]\\s|\\n\\n', text_fr) if x != \"\"]\n",
    "    sentences_en = [x.strip() for x in re.split(r'(?<![;,])[.?!]\\s|\\n\\n', text_en) if x != \"\"]\n",
    "    \n",
    "    return sentences_fr, sentences_en\n",
    "\n",
    "\n",
    "def create_similarity_matrix(sentences_fr, sentences_en, sentence_encoder):\n",
    "    embeddings_fr = sentence_encoder.encode(sentences_fr, convert_to_tensor=True)\n",
    "    embeddings_en = sentence_encoder.encode(sentences_en, convert_to_tensor=True)\n",
    "\n",
    "    return util.pytorch_cos_sim(embeddings_fr, embeddings_en)\n",
    "\n",
    "\n",
    "def align_sentences(sim_matrix, threshold=0.7):\n",
    "    n, m = sim_matrix.shape\n",
    "    \n",
    "    weights = np.where(sim_matrix >= threshold, sim_matrix, 0.0)\n",
    "    \n",
    "    dp = np.zeros((n+1, m+1), dtype=np.float32)\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, m+1):\n",
    "            score_match = dp[i-1, j-1] + weights[i-1, j-1]\n",
    "            score_skip_fr = dp[i-1, j]\n",
    "            score_skip_en = dp[i, j-1]\n",
    "            \n",
    "            dp[i, j] = max(score_match, score_skip_fr, score_skip_en)\n",
    "    \n",
    "    aligned_pairs = []\n",
    "    i, j = n, m\n",
    "    while i > 0 and j > 0:\n",
    "        current_val = dp[i, j]\n",
    "        if np.isclose(current_val, dp[i-1, j]):\n",
    "            i -= 1\n",
    "        elif np.isclose(current_val, dp[i, j-1]):\n",
    "            j -= 1\n",
    "        else:\n",
    "            if weights[i-1, j-1] > 0:\n",
    "                aligned_pairs.append((i-1, j-1))\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "    \n",
    "    aligned_pairs.reverse()\n",
    "    \n",
    "    return aligned_pairs\n",
    "\n",
    "\n",
    "def text_from_coordinates(aligned_pairs, sentences_fr, sentences_en, pub_number):\n",
    "    correlated_list = list()\n",
    "    for i, j in aligned_pairs:\n",
    "        correlated_list.append((pub_number, sentences_fr[i], sentences_en[j]))\n",
    "    \n",
    "    return correlated_list\n",
    "\n",
    "\n",
    "def correlate_and_clean_text(text_fr, text_en, pub_number, sentence_encoder):\n",
    "    sentences_fr, sentences_en = create_sentences(text_fr, text_en)\n",
    "    similarity_matrix = create_similarity_matrix(sentences_fr, sentences_en, sentence_encoder)\n",
    "    aligned_pairs = align_sentences(similarity_matrix)\n",
    "\n",
    "    return text_from_coordinates(aligned_pairs, sentences_fr, sentences_en, pub_number)\n",
    "\n",
    "\n",
    "def process_all_rows(fr_eng_correlation_df, parsed_docs_folder, clf, sentence_encoder):\n",
    "    matched_data = []\n",
    "    max_ratio = 2  # low quality / only abstract data to exclude (<7% of total translated data)\n",
    "    min_char = 1000  # low quality, bad OCR, or incomplete transcription / parsing\n",
    "    \n",
    "    with alive_bar(fr_eng_correlation_df.shape[0], force_tty=True) as bar:\n",
    "        for _, row in fr_eng_correlation_df.iterrows():\n",
    "            bar()\n",
    "            \n",
    "            pub_number = row['pub_number']\n",
    "            filename_fr, filename_en = row['filename_fr'], row['filename_en']\n",
    "            \n",
    "            if filename_fr == \"WITHDRAWN\" and filename_en == \"WITHDRAWN\":\n",
    "                continue\n",
    "            \n",
    "            fr_link = get_json_file_link(parsed_docs_folder, filename_fr)\n",
    "            if fr_link == None:\n",
    "                continue\n",
    "            \n",
    "            if filename_fr == filename_en:\n",
    "                text_fr, text_en = extract_both_languages_from_single_file(fr_link, clf)\n",
    "            else:\n",
    "                en_link = get_json_file_link(parsed_docs_folder, filename_en) \n",
    "                if en_link == None:\n",
    "                    continue\n",
    "                text_fr, text_en = extract_both_languages_from_two_files(fr_link, en_link, clf)\n",
    "            \n",
    "            # low-quality text criteria\n",
    "            len_fr, len_en = len(text_fr), len(text_en)\n",
    "            if len_fr == 0 or len_en == 0:\n",
    "                continue\n",
    "            elif len(text_fr) / len(text_en) > max_ratio:\n",
    "                continue\n",
    "            elif len(text_en) / len(text_fr) > max_ratio:\n",
    "                continue\n",
    "            elif len(text_fr) < min_char or len(text_en) < min_char:\n",
    "                continue\n",
    "            \n",
    "            list_of_correlated_text = correlate_and_clean_text(text_fr, text_en, pub_number, sentence_encoder)\n",
    "            matched_data.extend(list_of_correlated_text)\n",
    "        \n",
    "    return pd.DataFrame(matched_data, columns=['pub_number', 'fr', 'en'])\n"
   ],
   "id": "2677bfe14b892d1e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T23:50:19.367273Z",
     "start_time": "2025-02-18T19:39:35.388211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentence_encoder = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "language_classifier = LanguageClassifier()\n",
    "\n",
    "matched_df = process_all_rows(fr_eng_correlation_df, parsed_docs_folder, language_classifier, sentence_encoder)"
   ],
   "id": "89a46335416a3704",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|████████████████████████████████████████| 9061/9061 [100%] in 4:10:41.9 (0.60/s ▃▅▇ 98/9061 [1%] in 1:21 (~2:03:00, 1 ▁▃▅ 124/9061 [1%] in 1:40 (~1:59:00,  ▂▄▆ 124/9061 [1%] in 1:41 (~1:59:00,  ▇▇▅ 126/9061 [1%] in 1:41 (~2:00:00,  ▁▃▅ 146/9061 [2%] in 1:48 (~1:49:00,  █▆▄ 148/9061 [2%] in 1:50 (~1:50:00,  ▂▂▄ 148/9061 [2%] in 1:51 (~1:50:00,  ▁▃▅ 149/9061 [2%] in 1:54 (~1:52:00,  ▂▄▆ 160/9061 [2%] in 1:59 (~1:49:00,  ▆█▆ 171/9061 [2%] in 2:08 (~1:50:00,  ▁▃▅ 176/9061 [2%] in 2:12 (~1:50:00,  █▆▄ 176/9061 [2%] in 2:13 (~1:51:00,  ▃▁▃ 205/9061 [2%] in 2:22 (~1:41:00,  ▄▆█ 212/9061 [2%] in 2:42 (~1:52:00,  ▂▄▆ 212/9061 [2%] in 2:52 (~1:59:00,  ▂▄▆ 217/9061 [2%] in 2:55 (~1:58:00,  ▅▃▁ 217/9061 [2%] in 2:57 (~1:59:00,  ▇▇▅ 217/9061 [2%] in 3:07 (~2:06:00,  ▆█▆ 3315/9061 [37%] in 45:02 (~1:18:0 ▅▃▁ 3366/9061 [37%] in 45:08 (~1:16:0 █▆▄ 3396/9061 [37%] in 45:13 (~1:15:0 ▅▃▁ 3433/9061 [38%] in 45:21 (~1:14:0 ▅▃▁ 3621/9061 [40%] in 45:37 (~1:08:0 ▃▁▃ 3621/9061 [40%] in 45:40 (~1:08:0 ▄▂▂ 3732/9061 [41%] in 45:56 (~1:05:0 ▃▁▃ 3737/9061 [41%] in 45:56 (~1:05:0 ▇▅▃ 3748/9061 [41%] in 45:58 (~1:05:0 ▇▇▅ 3791/9061 [42%] in 46:06 (~1:04:0 ▁▃▅ 3797/9061 [42%] in 46:13 (~1:04:0 █▆▄ 3802/9061 [42%] in 46:25 (~1:04:0 ▂▄▆ 3824/9061 [42%] in 46:34 (~1:03:0 ▂▄▆ 3893/9061 [43%] in 46:45 (~1:02:0 ▆▄▂ 3894/9061 [43%] in 46:46 (~1:02:0 ▂▄▆ 3958/9061 [44%] in 47:14 (~1:00:0 █▆▄ 3971/9061 [44%] in 47:15 (~1:00:0 ▇▅▃ 3971/9061 [44%] in 47:18 (~1:00:0 ▃▅▇ 3986/9061 [44%] in 47:25 (~1:00:0 ▂▂▄ 3986/9061 [44%] in 47:27 (~1:00:0 ▂▄▆ 3986/9061 [44%] in 47:27 (~1:00:0 █▆▄ 3986/9061 [44%] in 47:28 (~1:00:0 ▅▃▁ 3992/9061 [44%] in 47:32 (~1:00:0 ▃▅▇ 4004/9061 [44%] in 47:43 (~1:00:0 ▄▆█ 4086/9061 [45%] in 47:59 (~58:20, ▇▇▅ 4087/9061 [45%] in 48:03 (~58:20, ▃▅▇ 4087/9061 [45%] in 48:05 (~58:30, ▁▃▅ 4110/9061 [45%] in 48:10 (~58:00, ▇▅▃ 4110/9061 [45%] in 48:14 (~58:00, ▆▄▂ 4118/9061 [45%] in 48:17 (~57:50, ▂▂▄ 4155/9061 [46%] in 48:36 (~57:20, ▅▇▇ 4267/9061 [47%] in 49:24 (~55:30, ▂▂▄ 4267/9061 [47%] in 49:26 (~55:30, ▃▅▇ 4335/9061 [48%] in 49:50 (~54:10, ▄▆█ 4335/9061 [48%] in 49:51 (~54:20, ▃▅▇ 4352/9061 [48%] in 49:53 (~54:00, ▇▇▅ 4352/9061 [48%] in 49:54 (~54:00, ▂▄▆ 4363/9061 [48%] in 50:04 (~53:50, ▇▅▃ 4371/9061 [48%] in 50:10 (~53:50, ▆▄▂ 4374/9061 [48%] in 50:16 (~53:50, ▅▇▇ 4374/9061 [48%] in 50:17 (~53:50, ▆▄▂ 4374/9061 [48%] in 50:21 (~53:50, ▄▂▂ 4376/9061 [48%] in 50:24 (~53:50, ▅▇▇ 4442/9061 [49%] in 50:44 (~52:40, ▃▁▃ 4463/9061 [49%] in 50:56 (~52:30, ▇▅▃ 4474/9061 [49%] in 50:58 (~52:20, ▆▄▂ 4496/9061 [50%] in 51:03 (~51:50, ▂▄▆ 4509/9061 [50%] in 51:15 (~51:40, ▆█▆ 4548/9061 [50%] in 51:34 (~51:10, ▄▆█ 4608/9061 [51%] in 52:00 (~50:10, ▂▄▆ 4623/9061 [51%] in 52:08 (~50:00, ▆█▆ 4623/9061 [51%] in 52:11 (~50:00, ▂▄▆ 4641/9061 [51%] in 52:16 (~49:40, ▆▄▂ 4659/9061 [51%] in 52:30 (~49:30, ▃▁▃ 4715/9061 [52%] in 53:01 (~48:50, ▂▂▄ 4731/9061 [52%] in 53:17 (~48:40, █▆▄ 4731/9061 [52%] in 53:21 (~48:40, ▆▄▂ 4739/9061 [52%] in 53:24 (~48:40, ▁▃▅ 4739/9061 [52%] in 53:25 (~48:40, ▃▁▃ 4771/9061 [53%] in 53:37 (~48:10, ▅▇▇ 4784/9061 [53%] in 53:39 (~47:50, ▇▇▅ 4859/9061 [54%] in 54:28 (~47:00, ▇▇▅ 4885/9061 [54%] in 54:35 (~46:30, █▆▄ 4885/9061 [54%] in 54:36 (~46:40, ▃▁▃ 4906/9061 [54%] in 54:49 (~46:20, ▄▂▂ 5199/9061 [57%] in 57:15 (~42:30, ▇▇▅ 5313/9061 [59%] in 58:05 (~41:00, ▄▆█ 5750/9061 [63%] in 1:01:11 (~35:1 ▄▆█ 5850/9061 [65%] in 1:04:03 (~35:0 ▃▅▇ 5864/9061 [65%] in 1:05:38 (~35:4 ▃▅▇ 5864/9061 [65%] in 1:06:03 (~36:0 ▂▄▆ 5867/9061 [65%] in 1:06:22 (~36:0 ▃▁▃ 5867/9061 [65%] in 1:06:29 (~36:1 ▄▆█ 5867/9061 [65%] in 1:06:33 (~36:1 ▁▃▅ 5870/9061 [65%] in 1:06:51 (~36:2 ▂▂▄ 5870/9061 [65%] in 1:07:02 (~36:2 ▃▅▇ 5870/9061 [65%] in 1:07:02 (~36:2 ▇▅▃ 5871/9061 [65%] in 1:07:14 (~36:3 ▃▁▃ 5872/9061 [65%] in 1:07:26 (~36:3 ▂▂▄ 5872/9061 [65%] in 1:07:28 (~36:3 ▇▅▃ 5872/9061 [65%] in 1:07:30 (~36:3 ▆▄▂ 5873/9061 [65%] in 1:07:33 (~36:4 ▂▂▄ 5873/9061 [65%] in 1:07:34 (~36:4 ▆█▆ 5873/9061 [65%] in 1:07:35 (~36:4 ▅▃▁ 5873/9061 [65%] in 1:07:36 (~36:4 ▇▇▅ 5874/9061 [65%] in 1:07:43 (~36:4 ▅▇▇ 5874/9061 [65%] in 1:07:46 (~36:4 ▆▄▂ 5877/9061 [65%] in 1:08:02 (~36:5 ▁▃▅ 5877/9061 [65%] in 1:08:06 (~36:5 ▇▇▅ 5877/9061 [65%] in 1:08:07 (~36:5 ▂▄▆ 5877/9061 [65%] in 1:08:14 (~36:5 ▇▅▃ 5877/9061 [65%] in 1:08:15 (~36:5 ▃▁▃ 5877/9061 [65%] in 1:08:16 (~36:5 ▃▅▇ 5877/9061 [65%] in 1:08:17 (~36:5 ▄▆█ 5880/9061 [65%] in 1:08:25 (~37:0 ▆▄▂ 5880/9061 [65%] in 1:08:32 (~37:0 ▃▅▇ 5880/9061 [65%] in 1:08:33 (~37:0 ▄▆█ 5883/9061 [65%] in 1:09:05 (~37:1 ▇▇▅ 5884/9061 [65%] in 1:09:16 (~37:2 ▃▁▃ 5886/9061 [65%] in 1:09:28 (~37:2 ▄▆█ 5887/9061 [65%] in 1:09:40 (~37:3 ▆▄▂ 5893/9061 [65%] in 1:10:18 (~37:4 ▅▃▁ 5896/9061 [65%] in 1:10:34 (~37:5 ▃▁▃ 5897/9061 [65%] in 1:10:38 (~37:5 ▆▄▂ 5899/9061 [65%] in 1:11:01 (~38:0 ▂▂▄ 5899/9061 [65%] in 1:11:02 (~38:0 ▁▃▅ 5899/9061 [65%] in 1:11:02 (~38:0 ▂▄▆ 5900/9061 [65%] in 1:11:16 (~38:1 ▅▃▁ 5900/9061 [65%] in 1:11:23 (~38:1 ▆▄▂ 5903/9061 [65%] in 1:11:36 (~38:1 ▅▃▁ 5903/9061 [65%] in 1:11:36 (~38:1 ▂▂▄ 5904/9061 [65%] in 1:11:48 (~38:2 █▆▄ 5906/9061 [65%] in 1:12:03 (~38:2 ▇▇▅ 5907/9061 [65%] in 1:12:05 (~38:2 ▄▆█ 5908/9061 [65%] in 1:12:13 (~38:3 ▇▇▅ 5908/9061 [65%] in 1:12:13 (~38:3 ▇▇▅ 5910/9061 [65%] in 1:12:21 (~38:3 ▆█▆ 5910/9061 [65%] in 1:12:26 (~38:3 ▂▄▆ 5913/9061 [65%] in 1:12:39 (~38:4 ▃▁▃ 5915/9061 [65%] in 1:12:44 (~38:4 ▄▆█ 5915/9061 [65%] in 1:12:44 (~38:4 ▃▅▇ 5915/9061 [65%] in 1:12:50 (~38:4 ▆█▆ 5915/9061 [65%] in 1:12:53 (~38:4 █▆▄ 5915/9061 [65%] in 1:13:04 (~38:5 ▃▁▃ 5916/9061 [65%] in 1:13:08 (~38:5 ▂▄▆ 5917/9061 [65%] in 1:13:19 (~38:5 ▂▄▆ 5919/9061 [65%] in 1:13:38 (~39:0 ▆█▆ 5919/9061 [65%] in 1:13:39 (~39:0 ▇▇▅ 5920/9061 [65%] in 1:13:44 (~39:0 ▁▃▅ 5921/9061 [65%] in 1:13:51 (~39:1 ▇▇▅ 5925/9061 [65%] in 1:14:19 (~39:2 ▇▇▅ 5925/9061 [65%] in 1:14:22 (~39:2 █▆▄ 5928/9061 [65%] in 1:14:35 (~39:2 █▆▄ 5928/9061 [65%] in 1:14:38 (~39:2 ▅▃▁ 5933/9061 [65%] in 1:15:00 (~39:3 ▄▆█ 5933/9061 [65%] in 1:15:01 (~39:3 ▆█▆ 5935/9061 [66%] in 1:15:18 (~39:3 ▄▆█ 5935/9061 [66%] in 1:15:20 (~39:4 █▆▄ 5936/9061 [66%] in 1:15:23 (~39:4 ▆█▆ 5936/9061 [66%] in 1:15:26 (~39:4 ▆▄▂ 5936/9061 [66%] in 1:15:26 (~39:4 ▇▅▃ 5937/9061 [66%] in 1:15:34 (~39:4 █▆▄ 5937/9061 [66%] in 1:15:39 (~39:4 ▆█▆ 5938/9061 [66%] in 1:15:52 (~39:5 █▆▄ 5938/9061 [66%] in 1:15:53 (~39:5 ▂▂▄ 5940/9061 [66%] in 1:16:05 (~39:5 ▄▂▂ 5940/9061 [66%] in 1:16:09 (~40:0 ▆█▆ 5941/9061 [66%] in 1:16:19 (~40:0 ▂▂▄ 5944/9061 [66%] in 1:16:50 (~40:1 ▇▅▃ 5945/9061 [66%] in 1:17:02 (~40:2 ▇▇▅ 5946/9061 [66%] in 1:17:07 (~40:2 ▁▃▅ 5948/9061 [66%] in 1:17:20 (~40:2 ▇▇▅ 5949/9061 [66%] in 1:17:26 (~40:3 ▇▇▅ 5949/9061 [66%] in 1:17:29 (~40:3 █▆▄ 5950/9061 [66%] in 1:17:45 (~40:3 ▁▃▅ 5953/9061 [66%] in 1:18:00 (~40:4 ▇▇▅ 5954/9061 [66%] in 1:18:04 (~40:4 ▆▄▂ 5954/9061 [66%] in 1:18:07 (~40:4 ▅▇▇ 5956/9061 [66%] in 1:18:14 (~40:4 ▇▅▃ 5956/9061 [66%] in 1:18:15 (~40:4 ▂▂▄ 5956/9061 [66%] in 1:18:18 (~40:4 ▆█▆ 5956/9061 [66%] in 1:18:25 (~40:5 ▁▃▅ 5958/9061 [66%] in 1:18:32 (~40:5 ▅▇▇ 5959/9061 [66%] in 1:18:35 (~40:5 ▃▅▇ 5959/9061 [66%] in 1:18:38 (~40:5 ▄▆█ 5960/9061 [66%] in 1:18:46 (~40:5 ▃▅▇ 5963/9061 [66%] in 1:19:07 (~41:0 █▆▄ 5963/9061 [66%] in 1:19:19 (~41:1 ▅▇▇ 5964/9061 [66%] in 1:19:24 (~41:1 ▁▃▅ 5967/9061 [66%] in 1:19:42 (~41:1 ▂▂▄ 5968/9061 [66%] in 1:19:44 (~41:1 ▅▇▇ 5968/9061 [66%] in 1:19:53 (~41:2 ▃▅▇ 5968/9061 [66%] in 1:19:55 (~41:2 ▂▄▆ 5968/9061 [66%] in 1:20:14 (~41:3 ▂▂▄ 5970/9061 [66%] in 1:20:44 (~41:4 ▇▅▃ 5972/9061 [66%] in 1:20:54 (~41:5 ▄▂▂ 5973/9061 [66%] in 1:20:58 (~41:5 ▆▄▂ 5973/9061 [66%] in 1:21:19 (~42:0 ▇▅▃ 5973/9061 [66%] in 1:21:24 (~42:0 ▇▅▃ 5974/9061 [66%] in 1:21:38 (~42:1 ▁▃▅ 5975/9061 [66%] in 1:21:54 (~42:1 ▆▄▂ 5975/9061 [66%] in 1:21:55 (~42:1 ▅▇▇ 5981/9061 [66%] in 1:23:08 (~42:4 ▂▂▄ 5984/9061 [66%] in 1:23:27 (~42:5 ▅▇▇ 6018/9061 [66%] in 1:28:05 (~44:3 ▇▇▅ 6023/9061 [66%] in 1:28:41 (~44:4 ▃▅▇ 6039/9061 [67%] in 1:30:45 (~45:2 ▅▃▁ 6043/9061 [67%] in 1:31:31 (~45:4 ▄▆█ 6044/9061 [67%] in 1:31:32 (~45:4 ▂▂▄ 6050/9061 [67%] in 1:32:29 (~46:0 ▅▇▇ 6050/9061 [67%] in 1:32:33 (~46:0 ▃▁▃ 6069/9061 [67%] in 1:35:58 (~47:1 ▇▇▅ 6082/9061 [67%] in 1:38:24 (~48:1 ▂▄▆ 6084/9061 [67%] in 1:39:41 (~48:4\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T23:50:20.339495Z",
     "start_time": "2025-02-18T23:50:19.377023Z"
    }
   },
   "cell_type": "code",
   "source": "matched_df.to_pickle(\"matched_data.pickle\")",
   "id": "bf44b1670443bcdc",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T23:50:20.353562Z",
     "start_time": "2025-02-18T23:50:20.349576Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4aff3b959c5ae708",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
