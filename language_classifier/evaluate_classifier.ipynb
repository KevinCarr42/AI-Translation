{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-03T16:59:36.477103Z",
     "start_time": "2025-02-03T16:59:35.772540Z"
    }
   },
   "source": [
    "import unicodedata\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from language_classifier import LanguageClassifier\n",
    "from faker import Faker\n",
    "\n",
    "faker_en = Faker('en_US')\n",
    "faker_fr = Faker('fr_FR')\n",
    "faker_es = Faker('es_ES')\n",
    "    \n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\")) # jupyter notebook full-width display\n",
    "display(HTML(\"<style>.dataframe td { white-space: nowrap; }</style>\")) # no text wrapping\n",
    "\n",
    "# pandas formatting\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "\n",
    "with open(\"example_sentences.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    sentences = json.load(f)\n",
    "    "
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>.dataframe td { white-space: nowrap; }</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T16:59:36.505184Z",
     "start_time": "2025-02-03T16:59:36.500802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_classifier(classifier, sentences, n_trials, tolerance_list):\n",
    "    results = []\n",
    "\n",
    "    for tolerance in tolerance_list:\n",
    "        for k, v in sentences.items():\n",
    "            for sentence in random.sample(v, n_trials):\n",
    "                classification = classifier.classify(sentence, tolerance) \n",
    "                results.append([tolerance, k, classification, sentence])\n",
    "\n",
    "    df = pd.DataFrame(results, columns=['tolerance', 'language', 'classification', 'sentence'])\n",
    "\n",
    "    df['is_correct'] = df['classification'] == df['language']\n",
    "    df['fr_false_positive'] = (df['classification'] == 'fr') & (df['language'] == 'en')\n",
    "    df['fr_false_negative'] = (df['classification'] != 'fr') & (df['language'] == 'fr')\n",
    "    df['en_false_positive'] = (df['classification'] == 'en') & (df['language'] == 'fr')\n",
    "    df['en_false_negative'] = (df['classification'] != 'en') & (df['language'] == 'en')\n",
    "\n",
    "    return df"
   ],
   "id": "ca64927e9115534b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T16:59:36.638877Z",
     "start_time": "2025-02-03T16:59:36.632080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_stats(results_df):\n",
    "    grouped_df = results_df.groupby('tolerance').agg(\n",
    "        total_count=('is_correct', 'count'),  # count rows (not the same as results_df['total_count']\n",
    "\n",
    "        # Correct and incorrect classifications\n",
    "        correct_count=('is_correct', 'sum'),\n",
    "        wrong_count=('is_correct', lambda x: (~x).sum()),  \n",
    "\n",
    "        # False Positives & False Negatives for each language\n",
    "        fr_false_positive=('fr_false_positive', 'sum'),\n",
    "        fr_false_negative=('fr_false_negative', 'sum'),\n",
    "        en_false_positive=('en_false_positive', 'sum'),\n",
    "        en_false_negative=('en_false_negative', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Avoid division by zero\n",
    "    valid_mask = grouped_df['total_count'] > 0\n",
    "\n",
    "    # Accuracy (same for both languages)\n",
    "    grouped_df['accuracy'] = np.where(valid_mask, grouped_df['correct_count'] / grouped_df['total_count'], 0)\n",
    "\n",
    "    # Precision & Recall for French\n",
    "    fr_precision_mask = (grouped_df['correct_count'] + grouped_df['fr_false_positive']) > 0\n",
    "    grouped_df['fr_precision'] = np.where(\n",
    "        fr_precision_mask, \n",
    "        grouped_df['correct_count'] / (grouped_df['correct_count'] + grouped_df['fr_false_positive']), \n",
    "        0\n",
    "    )\n",
    "\n",
    "    fr_recall_mask = (grouped_df['correct_count'] + grouped_df['fr_false_negative']) > 0\n",
    "    grouped_df['fr_recall'] = np.where(\n",
    "        fr_recall_mask, \n",
    "        grouped_df['correct_count'] / (grouped_df['correct_count'] + grouped_df['fr_false_negative']), \n",
    "        0\n",
    "    )\n",
    "\n",
    "    # Precision & Recall for English\n",
    "    en_precision_mask = (grouped_df['correct_count'] + grouped_df['en_false_positive']) > 0\n",
    "    grouped_df['en_precision'] = np.where(\n",
    "        en_precision_mask, \n",
    "        grouped_df['correct_count'] / (grouped_df['correct_count'] + grouped_df['en_false_positive']), \n",
    "        0\n",
    "    )\n",
    "\n",
    "    en_recall_mask = (grouped_df['correct_count'] + grouped_df['en_false_negative']) > 0\n",
    "    grouped_df['en_recall'] = np.where(\n",
    "        en_recall_mask, \n",
    "        grouped_df['correct_count'] / (grouped_df['correct_count'] + grouped_df['en_false_negative']), \n",
    "        0\n",
    "    )\n",
    "\n",
    "    # F1-scores\n",
    "    grouped_df['fr_f1_score'] = np.where(\n",
    "        (grouped_df['fr_precision'] + grouped_df['fr_recall']) > 0,\n",
    "        2 * (grouped_df['fr_precision'] * grouped_df['fr_recall']) / (grouped_df['fr_precision'] + grouped_df['fr_recall']),\n",
    "        0\n",
    "    )\n",
    "\n",
    "    grouped_df['en_f1_score'] = np.where(\n",
    "        (grouped_df['en_precision'] + grouped_df['en_recall']) > 0,\n",
    "        2 * (grouped_df['en_precision'] * grouped_df['en_recall']) / (grouped_df['en_precision'] + grouped_df['en_recall']),\n",
    "        0\n",
    "    )\n",
    "\n",
    "    # Sum of statistics (optional, useful for ranking)\n",
    "    grouped_df['recall_avg'] = grouped_df[['fr_recall', 'en_recall']].mean(axis=1)\n",
    "    grouped_df['precision_avg'] = grouped_df[['fr_precision', 'en_precision']].mean(axis=1)\n",
    "    grouped_df['f1_score_avg'] = grouped_df[['fr_f1_score', 'en_f1_score']].mean(axis=1)\n",
    "    grouped_df['all_stats_avg'] = grouped_df[['accuracy', 'fr_precision', 'fr_recall', 'en_precision', 'en_recall', 'fr_f1_score', 'en_f1_score']].mean(axis=1)\n",
    "\n",
    "    return grouped_df\n"
   ],
   "id": "9d506a47bebb1e08",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T16:59:37.098686Z",
     "start_time": "2025-02-03T16:59:36.646630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n = 10000\n",
    "tolerances = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "clf = LanguageClassifier()\n",
    "\n",
    "df = evaluate_classifier(clf, sentences, n, tolerances)\n",
    "grouped_df = create_stats(df)\n",
    "\n",
    "grouped_df.T"
   ],
   "id": "1be26e8c02fff764",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                         0        1        2        3        4        5\n",
       "tolerance             0.00     1.00     2.00     3.00     4.00     5.00\n",
       "total_count       20000.00 20000.00 20000.00 20000.00 20000.00 20000.00\n",
       "correct_count     18683.00 19872.00 19890.00 19850.00 19804.00 19700.00\n",
       "wrong_count        1317.00   128.00   110.00   150.00   196.00   300.00\n",
       "fr_false_positive     2.00     6.00     2.00     7.00     3.00     4.00\n",
       "fr_false_negative   988.00    69.00    56.00    88.00   150.00   253.00\n",
       "en_false_positive     1.00     6.00    39.00    76.00   141.00   242.00\n",
       "en_false_negative   329.00    59.00    54.00    62.00    46.00    47.00\n",
       "accuracy              0.93     0.99     0.99     0.99     0.99     0.98\n",
       "fr_precision          1.00     1.00     1.00     1.00     1.00     1.00\n",
       "fr_recall             0.95     1.00     1.00     1.00     0.99     0.99\n",
       "en_precision          1.00     1.00     1.00     1.00     0.99     0.99\n",
       "en_recall             0.98     1.00     1.00     1.00     1.00     1.00\n",
       "fr_f1_score           0.97     1.00     1.00     1.00     1.00     0.99\n",
       "en_f1_score           0.99     1.00     1.00     1.00     1.00     0.99\n",
       "recall_avg            0.97     1.00     1.00     1.00     1.00     0.99\n",
       "precision_avg         1.00     1.00     1.00     1.00     1.00     0.99\n",
       "f1_score_avg          0.98     1.00     1.00     1.00     1.00     0.99\n",
       "all_stats_avg         0.98     1.00     1.00     1.00     0.99     0.99"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tolerance</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_count</th>\n",
       "      <td>20000.00</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>20000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correct_count</th>\n",
       "      <td>18683.00</td>\n",
       "      <td>19872.00</td>\n",
       "      <td>19890.00</td>\n",
       "      <td>19850.00</td>\n",
       "      <td>19804.00</td>\n",
       "      <td>19700.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrong_count</th>\n",
       "      <td>1317.00</td>\n",
       "      <td>128.00</td>\n",
       "      <td>110.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>196.00</td>\n",
       "      <td>300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_false_positive</th>\n",
       "      <td>2.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_false_negative</th>\n",
       "      <td>988.00</td>\n",
       "      <td>69.00</td>\n",
       "      <td>56.00</td>\n",
       "      <td>88.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>253.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en_false_positive</th>\n",
       "      <td>1.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>76.00</td>\n",
       "      <td>141.00</td>\n",
       "      <td>242.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en_false_negative</th>\n",
       "      <td>329.00</td>\n",
       "      <td>59.00</td>\n",
       "      <td>54.00</td>\n",
       "      <td>62.00</td>\n",
       "      <td>46.00</td>\n",
       "      <td>47.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_precision</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_recall</th>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en_precision</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en_recall</th>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_f1_score</th>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en_f1_score</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_avg</th>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_avg</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_avg</th>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_stats_avg</th>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T16:59:37.126318Z",
     "start_time": "2025-02-03T16:59:37.120825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# looks like 1-3 is the optimal tolerance range\n",
    "grouped_df[['all_stats_avg', 'f1_score_avg']]"
   ],
   "id": "11b3a363b7029cbb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   all_stats_avg  f1_score_avg\n",
       "0           0.98          0.98\n",
       "1           1.00          1.00\n",
       "2           1.00          1.00\n",
       "3           1.00          1.00\n",
       "4           0.99          1.00\n",
       "5           0.99          0.99"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_stats_avg</th>\n",
       "      <th>f1_score_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T16:59:37.172431Z",
     "start_time": "2025-02-03T16:59:37.163345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# should avoiding false negatives be priority? (exclude more to get better quality)\n",
    "#   tolerance range of 1-3 still looks good\n",
    "grouped_df[['fr_recall', 'en_recall', 'recall_avg']]"
   ],
   "id": "a9e6f59d2902ce1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   fr_recall  en_recall  recall_avg\n",
       "0       0.95       0.98        0.97\n",
       "1       1.00       1.00        1.00\n",
       "2       1.00       1.00        1.00\n",
       "3       1.00       1.00        1.00\n",
       "4       0.99       1.00        1.00\n",
       "5       0.99       1.00        0.99"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fr_recall</th>\n",
       "      <th>en_recall</th>\n",
       "      <th>recall_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# let's take a look at some mistakes",
   "id": "75f914876c78b014"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T16:59:37.287429Z",
     "start_time": "2025-02-03T16:59:37.269154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# first, let's drop everything that is not tolerance == 1\n",
    "\n",
    "df = df[df.tolerance == 1].reset_index(drop=True)"
   ],
   "id": "3655fa1b48f60c71",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T16:59:37.397168Z",
     "start_time": "2025-02-03T16:59:37.387655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# how many errors vs correct?\n",
    "(\n",
    "    df.loc[~df.is_correct, ['language', 'classification', 'sentence']].shape[0], \n",
    "    df.loc[df.is_correct, ['language', 'classification', 'sentence']].shape[0],\n",
    "    df.loc[~df.is_correct, ['language', 'classification', 'sentence']].shape[0] / df.loc[df.is_correct, ['language', 'classification', 'sentence']].shape[0]\n",
    " )"
   ],
   "id": "697e7678d16a3e1f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 19872, 0.00644122383252818)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T16:59:37.490875Z",
     "start_time": "2025-02-03T16:59:37.469526Z"
    }
   },
   "cell_type": "code",
   "source": "df.loc[~df.is_correct, ['language', 'classification', 'sentence']]",
   "id": "72bb5d1e39a3459d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      language classification  \\\n",
       "103         en          mixed   \n",
       "572         en        unknown   \n",
       "841         en        unknown   \n",
       "972         en        unknown   \n",
       "1147        en        unknown   \n",
       "...        ...            ...   \n",
       "19649       fr          mixed   \n",
       "19765       fr             en   \n",
       "19893       fr          mixed   \n",
       "19899       fr             en   \n",
       "19926       fr          mixed   \n",
       "\n",
       "                                                                                                                    sentence  \n",
       "103                            dispersion dispersion is complex and the rates depend on many factors water velocity shears i  \n",
       "572                                            status of the pacific whitesided dolphin lagenorhynchus obliquidens in canada  \n",
       "841                                                                               wildland hydrology pagosa springs colorado  \n",
       "972                                                                                  war civil unrest and military exercises  \n",
       "1147                                                                        cacsassccs assessment of the northern gulf of st  \n",
       "...                                                                                                                      ...  \n",
       "19649  une allocation de tonnes est prévue pour la composante du banc de georges mais aucun débarquement na été déclaré pour  \n",
       "19765                                     et des connaissances traditionnelles des inuit inuit qaujimajatuqangit lewis et al  \n",
       "19893                   le long des voies migratoires empruntées par plusieurs populations de march et maiers de march et al  \n",
       "19899                                           liparis liparis liparis bathyarcticus limace nébuleuse à c mecklenburg et al  \n",
       "19926                                                        le schem est basé sur une hiérarchie conceptuelle de last et al  \n",
       "\n",
       "[128 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>classification</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>en</td>\n",
       "      <td>mixed</td>\n",
       "      <td>dispersion dispersion is complex and the rates depend on many factors water velocity shears i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>en</td>\n",
       "      <td>unknown</td>\n",
       "      <td>status of the pacific whitesided dolphin lagenorhynchus obliquidens in canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>en</td>\n",
       "      <td>unknown</td>\n",
       "      <td>wildland hydrology pagosa springs colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>en</td>\n",
       "      <td>unknown</td>\n",
       "      <td>war civil unrest and military exercises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>en</td>\n",
       "      <td>unknown</td>\n",
       "      <td>cacsassccs assessment of the northern gulf of st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19649</th>\n",
       "      <td>fr</td>\n",
       "      <td>mixed</td>\n",
       "      <td>une allocation de tonnes est prévue pour la composante du banc de georges mais aucun débarquement na été déclaré pour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19765</th>\n",
       "      <td>fr</td>\n",
       "      <td>en</td>\n",
       "      <td>et des connaissances traditionnelles des inuit inuit qaujimajatuqangit lewis et al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19893</th>\n",
       "      <td>fr</td>\n",
       "      <td>mixed</td>\n",
       "      <td>le long des voies migratoires empruntées par plusieurs populations de march et maiers de march et al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19899</th>\n",
       "      <td>fr</td>\n",
       "      <td>en</td>\n",
       "      <td>liparis liparis liparis bathyarcticus limace nébuleuse à c mecklenburg et al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19926</th>\n",
       "      <td>fr</td>\n",
       "      <td>mixed</td>\n",
       "      <td>le schem est basé sur une hiérarchie conceptuelle de last et al</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T16:59:37.531632Z",
     "start_time": "2025-02-03T16:59:37.525904Z"
    }
   },
   "cell_type": "code",
   "source": "df.loc[~df.is_correct, ['classification']].value_counts()",
   "id": "8b72ab02a6a6643c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classification\n",
       "mixed             68\n",
       "unknown           48\n",
       "en                 6\n",
       "fr                 6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Generate Fake Sentences - Test the Classifier",
   "id": "88b4ac158b69616d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T16:59:38.155197Z",
     "start_time": "2025-02-03T16:59:37.611284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_non_alphabetic_sentence(length):\n",
    "    characters = string.digits + string.punctuation + \" \" * 30 + \"|\" * 5\n",
    "    sentence = \"\".join(random.choices(characters, k=length))\n",
    "    sentence = sentence.replace(\" \", \" \" * random.randint(2, 4))\n",
    "    return sentence\n",
    "\n",
    "def generate_fake_sentence(sentence_type):\n",
    "    min_words, max_words = 10, 15\n",
    "    n_words = random.choice(range(min_words, max_words + 1))\n",
    "    \n",
    "    if sentence_type == 'en':\n",
    "        return faker_en.sentence(n_words)\n",
    "    elif sentence_type == 'fr':\n",
    "        return faker_fr.sentence(n_words)\n",
    "    elif sentence_type == 'mixed':\n",
    "        words_en = faker_en.sentence(n_words).split()\n",
    "        words_fr = faker_fr.sentence(n_words).split()\n",
    "        return random.choice([\n",
    "            \" \".join(words_en[:n_words // 2] + words_fr[n_words // 2:]), \n",
    "            \" \".join(words_fr[:n_words // 2] + words_en[n_words // 2:])\n",
    "        ])\n",
    "    elif sentence_type == 'unknown':\n",
    "        return random.choice([\n",
    "            faker_es.sentence(n_words), \n",
    "            generate_non_alphabetic_sentence(n_words * 5)\n",
    "        ])\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "n_trials = 10000\n",
    "fake_sentences = dict()\n",
    "\n",
    "for language in ['en', 'fr', 'mixed', 'unknown']:\n",
    "    fake_sentences[language] = list()\n",
    "    for _ in range(n_trials):\n",
    "        fake_sentences[language].append(generate_fake_sentence(language))\n",
    "        "
   ],
   "id": "a105c48c8e310c91",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T16:59:38.176154Z",
     "start_time": "2025-02-03T16:59:38.158620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# re-write / overwrite evaluation and statistics functions\n",
    "\n",
    "def evaluate_classifier(classifier, sentences, n_trials, tolerance_list):\n",
    "    results = []\n",
    "    \n",
    "    for tolerance in tolerance_list:\n",
    "        for k, v in sentences.items():\n",
    "            for sentence in random.sample(v, n_trials):\n",
    "                classification = classifier.classify(sentence, tolerance) \n",
    "                results.append([tolerance, k, classification, sentence])\n",
    "                \n",
    "    df = pd.DataFrame(results, columns=['tolerance', 'language', 'classification', 'sentence'])\n",
    "    \n",
    "    # Correct classification\n",
    "    df['is_correct'] = df['classification'] == df['language']\n",
    "\n",
    "    # False positives (Predicted X but should be Y)\n",
    "    df['fr_false_positive'] = (df['classification'] == 'fr') & (df['language'] != 'fr')\n",
    "    df['en_false_positive'] = (df['classification'] == 'en') & (df['language'] != 'en')\n",
    "    df['mixed_false_positive'] = (df['classification'] == 'mixed') & (df['language'] != 'mixed')\n",
    "    df['unknown_false_positive'] = (df['classification'] == 'unknown') & (df['language'] != 'unknown')\n",
    "\n",
    "    # False negatives (Should be X but classified as something else)\n",
    "    df['fr_false_negative'] = (df['classification'] != 'fr') & (df['language'] == 'fr')\n",
    "    df['en_false_negative'] = (df['classification'] != 'en') & (df['language'] == 'en')\n",
    "    df['mixed_false_negative'] = (df['classification'] != 'mixed') & (df['language'] == 'mixed')\n",
    "    df['unknown_false_negative'] = (df['classification'] != 'unknown') & (df['language'] == 'unknown')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_stats(results_df):\n",
    "    grouped_df = results_df.groupby('tolerance').agg(\n",
    "        total_count=('is_correct', 'count'),  # Total rows\n",
    "        \n",
    "        # Correct and incorrect classifications\n",
    "        correct_count=('is_correct', 'sum'),\n",
    "        wrong_count=('is_correct', lambda x: (~x).sum()),  \n",
    "\n",
    "        # False Positives & False Negatives for each category\n",
    "        fr_false_positive=('fr_false_positive', 'sum'),\n",
    "        fr_false_negative=('fr_false_negative', 'sum'),\n",
    "        en_false_positive=('en_false_positive', 'sum'),\n",
    "        en_false_negative=('en_false_negative', 'sum'),\n",
    "        mixed_false_positive=('mixed_false_positive', 'sum'),\n",
    "        mixed_false_negative=('mixed_false_negative', 'sum'),\n",
    "        unknown_false_positive=('unknown_false_positive', 'sum'),\n",
    "        unknown_false_negative=('unknown_false_negative', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Avoid division by zero\n",
    "    valid_mask = grouped_df['total_count'] > 0\n",
    "\n",
    "    # Accuracy\n",
    "    grouped_df['accuracy'] = np.where(valid_mask, grouped_df['correct_count'] / grouped_df['total_count'], 0)\n",
    "\n",
    "    # Helper function for precision and recall\n",
    "    def calc_precision(correct, false_pos):\n",
    "        return np.where((correct + false_pos) > 0, correct / (correct + false_pos), 0)\n",
    "\n",
    "    def calc_recall(correct, false_neg):\n",
    "        return np.where((correct + false_neg) > 0, correct / (correct + false_neg), 0)\n",
    "\n",
    "    def calc_f1(precision, recall):\n",
    "        return np.where((precision + recall) > 0, 2 * (precision * recall) / (precision + recall), 0)\n",
    "\n",
    "    # Precision & Recall for French\n",
    "    grouped_df['fr_precision'] = calc_precision(grouped_df['correct_count'], grouped_df['fr_false_positive'])\n",
    "    grouped_df['fr_recall'] = calc_recall(grouped_df['correct_count'], grouped_df['fr_false_negative'])\n",
    "\n",
    "    # Precision & Recall for English\n",
    "    grouped_df['en_precision'] = calc_precision(grouped_df['correct_count'], grouped_df['en_false_positive'])\n",
    "    grouped_df['en_recall'] = calc_recall(grouped_df['correct_count'], grouped_df['en_false_negative'])\n",
    "\n",
    "    # Precision & Recall for Mixed\n",
    "    grouped_df['mixed_precision'] = calc_precision(grouped_df['correct_count'], grouped_df['mixed_false_positive'])\n",
    "    grouped_df['mixed_recall'] = calc_recall(grouped_df['correct_count'], grouped_df['mixed_false_negative'])\n",
    "\n",
    "    # Precision & Recall for Unknown\n",
    "    grouped_df['unknown_precision'] = calc_precision(grouped_df['correct_count'], grouped_df['unknown_false_positive'])\n",
    "    grouped_df['unknown_recall'] = calc_recall(grouped_df['correct_count'], grouped_df['unknown_false_negative'])\n",
    "\n",
    "    # F1-scores\n",
    "    grouped_df['fr_f1_score'] = calc_f1(grouped_df['fr_precision'], grouped_df['fr_recall'])\n",
    "    grouped_df['en_f1_score'] = calc_f1(grouped_df['en_precision'], grouped_df['en_recall'])\n",
    "    grouped_df['mixed_f1_score'] = calc_f1(grouped_df['mixed_precision'], grouped_df['mixed_recall'])\n",
    "    grouped_df['unknown_f1_score'] = calc_f1(grouped_df['unknown_precision'], grouped_df['unknown_recall'])\n",
    "\n",
    "    # Sum of statistics (optional, useful for ranking)\n",
    "    grouped_df['all_recall_avg'] = grouped_df[['fr_recall', 'en_recall', 'mixed_recall', 'unknown_recall']].mean(axis=1)\n",
    "    grouped_df['all_precision_avg'] = grouped_df[['fr_precision', 'en_precision', 'mixed_precision', 'unknown_precision']].mean(axis=1)\n",
    "    grouped_df['all_f1_score_avg'] = grouped_df[['fr_f1_score', 'en_f1_score', 'mixed_f1_score', 'unknown_f1_score']].mean(axis=1)\n",
    "    grouped_df['all_stats_avg'] = grouped_df[\n",
    "        ['accuracy', 'fr_precision', 'fr_recall', 'en_precision', 'en_recall',\n",
    "         'mixed_precision', 'mixed_recall', 'unknown_precision', 'unknown_recall',\n",
    "         'fr_f1_score', 'en_f1_score', 'mixed_f1_score', 'unknown_f1_score']\n",
    "    ].mean(axis=1)\n",
    "\n",
    "    return grouped_df\n"
   ],
   "id": "746ef84431fe341a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T16:59:39.131266Z",
     "start_time": "2025-02-03T16:59:38.193176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n = 10000\n",
    "tolerances = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "clf = LanguageClassifier()\n",
    "\n",
    "df = evaluate_classifier(clf, fake_sentences, n, tolerances)\n",
    "grouped_df = create_stats(df)\n"
   ],
   "id": "9506546bd0fb85c1",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T17:02:36.357008Z",
     "start_time": "2025-02-03T17:02:36.348071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# zero tolerance seems best for fake sentences / clean data\n",
    "grouped_df[['tolerance', 'accuracy', 'all_recall_avg', 'all_precision_avg', 'all_f1_score_avg', 'all_stats_avg']]"
   ],
   "id": "5256a067aa614ec0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   tolerance  accuracy  all_recall_avg  all_precision_avg  all_f1_score_avg  \\\n",
       "0          0      0.80            0.94               0.94              0.94   \n",
       "1          1      0.75            0.93               0.93              0.92   \n",
       "2          2      0.69            0.91               0.91              0.90   \n",
       "3          3      0.67            0.90               0.90              0.89   \n",
       "4          4      0.66            0.90               0.90              0.89   \n",
       "5          5      0.66            0.90               0.90              0.89   \n",
       "\n",
       "   all_stats_avg  \n",
       "0           0.93  \n",
       "1           0.91  \n",
       "2           0.89  \n",
       "3           0.88  \n",
       "4           0.88  \n",
       "5           0.88  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tolerance</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>all_recall_avg</th>\n",
       "      <th>all_precision_avg</th>\n",
       "      <th>all_f1_score_avg</th>\n",
       "      <th>all_stats_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# CONCLUSION\n",
    "#### use tolerance 1 as default to balance between CSAS results (1-3) and clean sentences (0)"
   ],
   "id": "54af8772fa63714c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T17:02:17.096398Z",
     "start_time": "2025-02-03T17:02:17.092898Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3bb68499a0a79e02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T17:02:17.392381Z",
     "start_time": "2025-02-03T17:02:17.389317Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "47ca2e6cc435230e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "617e4083ec289878"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
